{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcelodeFreitas/udemy_deep_learning_pytorch_python/blob/main/Projeto_3_Classifica%C3%A7%C3%A3o_bin%C3%A1ria_breast_cancer_com_tuning_de_par%C3%A2metros.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_RSER5Lkb5"
      },
      "source": [
        "# Projeto 3: Classificação binária brest cancer com tuning dos parâmetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tP2BcEILoLB"
      },
      "source": [
        "## Etapa 1: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGW4fwZmkw6l",
        "outputId": "3ee5d69a-1092-42f8-d5ad-bb3b64c0edd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skorch in c:\\users\\pc\\documents\\github\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\pc\\documents\\github\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages (from skorch) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\pc\\documents\\github\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages (from skorch) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\pc\\documents\\github\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages (from skorch) (1.7.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\pc\\documents\\github\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in c:\\users\\pc\\documents\\github\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages (from skorch) (4.66.1)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\pc\\documents\\github\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages (from scikit-learn>=0.22.0->skorch) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\pc\\documents\\github\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages (from scikit-learn>=0.22.0->skorch) (3.1.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\pc\\documents\\github\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages (from tqdm>=4.14.0->skorch) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Yf0FpJ35Lf-Z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import skorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from skorch import NeuralNetBinaryClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WN4QmB303kQ",
        "outputId": "2b46dc7c-f5df-46f2-fa82-31be78c9ad79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('1.13.1+cpu', '0.13.0', '1.0.2')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__, skorch.__version__, sklearn.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0SD4dJ4MDMN"
      },
      "source": [
        "## Etapa 2: Base de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9aIu62WMGo8",
        "outputId": "a082f689-da8b-4f08-bbed-99a9d972513f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x2334bd5a2f0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u49yuDE9MJs6"
      },
      "outputs": [],
      "source": [
        "previsores = pd.read_csv('./databases/entradas_breast.csv')\n",
        "classe = pd.read_csv('./databases/saidas_breast.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_fQ_cVSei2Bp"
      },
      "outputs": [],
      "source": [
        "previsores = np.array(previsores, dtype = 'float32')\n",
        "classe = np.array(classe, dtype = 'float32').squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6taWVK8i_PW",
        "outputId": "958e6c5e-a27c-426f-d520-ba1d822ee9ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "previsores.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeQ3eYXfjByQ",
        "outputId": "6896692d-1644-4c87-fdf3-1a7d88720d70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classe.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MI0xnzWjSJg"
      },
      "source": [
        "## Etapa 3: Classe para estrutura da rede neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBrLNkL02ar2"
      },
      "source": [
        "**\\*\\* ATUALIZAÇÃO JAN/2022 \\*\\*** : na versão atual do Skorch, os resultados da rede neural devem ser retornados sem ativação, ou seja, sem a camada sigmoide no final. Com isto, a função de custo deve ser `BCEWithLogitsLoss`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "s5WkE5vmQjjX"
      },
      "outputs": [],
      "source": [
        "class classificador_torch(nn.Module):\n",
        "  def __init__(self, activation, neurons, initializer):\n",
        "    super().__init__()\n",
        "    # 30 -> 16 -> 16 -> 1\n",
        "    self.dense0 = nn.Linear(30, neurons)\n",
        "    initializer(self.dense0.weight)\n",
        "    self.activation0 = activation\n",
        "    self.dense1 = nn.Linear(neurons, neurons)\n",
        "    initializer(self.dense1.weight)\n",
        "    self.activation1 = activation\n",
        "    self.dense2 = nn.Linear(neurons, 1)\n",
        "    initializer(self.dense2.weight)\n",
        "    # self.output = nn.Sigmoid() ** ATUALIZAÇÃO (ver detalhes no texto acima) **\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.dense0(X)\n",
        "    X = self.activation0(X)\n",
        "    X = self.dense1(X)\n",
        "    X = self.activation1(X)\n",
        "    X = self.dense2(X)\n",
        "    # X = self.output(X) ** ATUALIZAÇÃO (ver detalhes no texto acima) **\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kstsTBpKj3yO"
      },
      "source": [
        "## Etapa 4: Skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gXdmN9NxSGQo"
      },
      "outputs": [],
      "source": [
        "classificador_sklearn = NeuralNetBinaryClassifier(module=classificador_torch,\n",
        "                                                  lr = 0.001,\n",
        "                                                  optimizer__weight_decay = 0.0001,\n",
        "                                                  train_split=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzxX25OfpQsc"
      },
      "source": [
        "## Etapa 5: Tuning dos parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qjDt9Ob5SwH4"
      },
      "outputs": [],
      "source": [
        "params = {'batch_size': [10],\n",
        "          'max_epochs': [100],\n",
        "          'optimizer': [torch.optim.Adam, torch.optim.SGD],\n",
        "          'criterion': [torch.nn.BCEWithLogitsLoss], #, torch.nn.HingeEmbeddingLoss], # ** ATUALIZAÇÃO **\n",
        "          'module__activation': [F.relu, F.tanh],\n",
        "          'module__neurons': [8, 16],\n",
        "          'module__initializer': [torch.nn.init.uniform]} # _, torch.nn.init.normal_]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ6R_ve1UKDY",
        "outputId": "238b0b31-ddc2-4e20-e5b6-af07a935e906"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'batch_size': [10],\n",
              " 'max_epochs': [100],\n",
              " 'optimizer': [torch.optim.adam.Adam, torch.optim.sgd.SGD],\n",
              " 'criterion': [torch.nn.modules.loss.BCEWithLogitsLoss],\n",
              " 'module__activation': [<function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
              "  <function torch.nn.functional.tanh(input)>],\n",
              " 'module__neurons': [8, 16],\n",
              " 'module__initializer': [<function torch.nn.init._make_deprecate.<locals>.deprecated_init(*args, **kwargs)>]}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL_8ya40UMy4",
        "outputId": "e8e69fff-9c8e-4bad-ef5f-3e8d1c2aa04a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m27299.8738\u001b[0m  0.0884\n",
            "      2    \u001b[36m24343.2038\u001b[0m  0.0677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      3    \u001b[36m21607.9801\u001b[0m  0.0455\n",
            "      4    \u001b[36m19135.1209\u001b[0m  0.0457\n",
            "      5    \u001b[36m16931.4981\u001b[0m  0.0511\n",
            "      6    \u001b[36m14986.2359\u001b[0m  0.0418\n",
            "      7    \u001b[36m13263.7468\u001b[0m  0.0407\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      8    \u001b[36m11731.9746\u001b[0m  0.0429\n",
            "      9    \u001b[36m10367.9507\u001b[0m  0.0395\n",
            "     10     \u001b[36m9150.4845\u001b[0m  0.0452\n",
            "     11     \u001b[36m8060.7275\u001b[0m  0.0664\n",
            "     12     \u001b[36m7080.4200\u001b[0m  0.0448\n",
            "     13     \u001b[36m6192.2921\u001b[0m  0.0422\n",
            "     14     \u001b[36m5382.8836\u001b[0m  0.0353\n",
            "     15     \u001b[36m4640.1406\u001b[0m  0.0366\n",
            "     16     \u001b[36m3952.5612\u001b[0m  0.0357\n",
            "     17     \u001b[36m3309.9056\u001b[0m  0.0357\n",
            "     18     \u001b[36m2702.8676\u001b[0m  0.0350\n",
            "     19     \u001b[36m2122.0807\u001b[0m  0.0341\n",
            "     20     \u001b[36m1558.6194\u001b[0m  0.0336\n",
            "     21     \u001b[36m1003.4049\u001b[0m  0.0363\n",
            "     22      \u001b[36m478.4398\u001b[0m  0.0338\n",
            "     23      \u001b[36m138.4234\u001b[0m  0.0333\n",
            "     24       \u001b[36m90.7292\u001b[0m  0.0341\n",
            "     25       \u001b[36m88.3919\u001b[0m  0.0339\n",
            "     26       \u001b[36m77.7052\u001b[0m  0.0302\n",
            "     27       \u001b[36m70.4368\u001b[0m  0.0351\n",
            "     28       \u001b[36m64.3089\u001b[0m  0.0308\n",
            "     29       \u001b[36m58.6982\u001b[0m  0.0351\n",
            "     30       \u001b[36m54.5392\u001b[0m  0.0333\n",
            "     31       \u001b[36m52.0839\u001b[0m  0.0356\n",
            "     32       \u001b[36m48.6802\u001b[0m  0.0351\n",
            "     33       \u001b[36m46.1668\u001b[0m  0.0338\n",
            "     34       \u001b[36m44.8264\u001b[0m  0.0348\n",
            "     35       \u001b[36m43.1170\u001b[0m  0.0366\n",
            "     36       \u001b[36m41.1273\u001b[0m  0.0360\n",
            "     37       \u001b[36m40.8537\u001b[0m  0.0339\n",
            "     38       \u001b[36m40.7872\u001b[0m  0.0341\n",
            "     39       42.1396  0.0361\n",
            "     40       \u001b[36m39.8864\u001b[0m  0.0347\n",
            "     41       \u001b[36m37.9433\u001b[0m  0.0351\n",
            "     42       \u001b[36m36.3551\u001b[0m  0.0366\n",
            "     43       \u001b[36m36.2228\u001b[0m  0.0354\n",
            "     44       \u001b[36m35.5409\u001b[0m  0.0380\n",
            "     45       \u001b[36m34.3930\u001b[0m  0.0402\n",
            "     46       \u001b[36m33.9006\u001b[0m  0.0384\n",
            "     47       34.1497  0.0374\n",
            "     48       \u001b[36m33.6520\u001b[0m  0.0348\n",
            "     49       34.2757  0.0316\n",
            "     50       34.4159  0.0358\n",
            "     51       \u001b[36m33.4091\u001b[0m  0.0331\n",
            "     52       \u001b[36m33.3076\u001b[0m  0.0351\n",
            "     53       \u001b[36m32.6955\u001b[0m  0.0343\n",
            "     54       \u001b[36m31.9610\u001b[0m  0.0311\n",
            "     55       \u001b[36m31.2410\u001b[0m  0.0594\n",
            "     56       \u001b[36m30.4211\u001b[0m  0.0351\n",
            "     57       \u001b[36m30.0836\u001b[0m  0.0304\n",
            "     58       \u001b[36m29.8696\u001b[0m  0.0308\n",
            "     59       \u001b[36m29.7572\u001b[0m  0.0334\n",
            "     60       \u001b[36m29.4924\u001b[0m  0.0312\n",
            "     61       \u001b[36m29.1599\u001b[0m  0.0327\n",
            "     62       \u001b[36m28.8134\u001b[0m  0.0362\n",
            "     63       \u001b[36m28.4562\u001b[0m  0.0303\n",
            "     64       29.0982  0.0398\n",
            "     65       28.7392  0.0307\n",
            "     66       28.6527  0.0389\n",
            "     67       28.6344  0.0329\n",
            "     68       \u001b[36m28.3827\u001b[0m  0.0313\n",
            "     69       \u001b[36m28.2495\u001b[0m  0.0347\n",
            "     70       \u001b[36m27.5174\u001b[0m  0.0310\n",
            "     71       \u001b[36m26.0215\u001b[0m  0.0401\n",
            "     72       \u001b[36m24.9014\u001b[0m  0.0293\n",
            "     73       \u001b[36m22.6375\u001b[0m  0.0346\n",
            "     74       22.7384  0.0300\n",
            "     75       \u001b[36m22.5511\u001b[0m  0.0397\n",
            "     76       \u001b[36m22.4552\u001b[0m  0.0300\n",
            "     77       22.4942  0.0400\n",
            "     78       \u001b[36m22.3393\u001b[0m  0.0292\n",
            "     79       22.4543  0.0288\n",
            "     80       \u001b[36m21.7850\u001b[0m  0.0311\n",
            "     81       21.9415  0.0297\n",
            "     82       22.1496  0.0364\n",
            "     83       22.0846  0.0332\n",
            "     84       23.0064  0.0267\n",
            "     85       25.1962  0.0406\n",
            "     86       25.4986  0.0350\n",
            "     87       26.9815  0.0308\n",
            "     88       27.3501  0.0415\n",
            "     89       26.5487  0.0382\n",
            "     90       25.8093  0.0301\n",
            "     91       24.4275  0.0308\n",
            "     92       26.0910  0.0318\n",
            "     93       23.6398  0.0331\n",
            "     94       26.5729  0.0308\n",
            "     95       23.3515  0.0400\n",
            "     96       26.5371  0.0338\n",
            "     97       22.2144  0.0322\n",
            "     98       26.2039  0.0303\n",
            "     99       22.0494  0.0377\n",
            "    100       24.7963  0.0311\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m20767.3644\u001b[0m  0.0402\n",
            "      2    \u001b[36m18392.6932\u001b[0m  0.0311\n",
            "      3    \u001b[36m16303.1933\u001b[0m  0.0356\n",
            "      4    \u001b[36m14403.4171\u001b[0m  0.0319\n",
            "      5    \u001b[36m12690.1414\u001b[0m  0.0282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6    \u001b[36m11149.3161\u001b[0m  0.0349\n",
            "      7     \u001b[36m9765.4890\u001b[0m  0.0354\n",
            "      8     \u001b[36m8523.4365\u001b[0m  0.0315\n",
            "      9     \u001b[36m7408.3099\u001b[0m  0.0300\n",
            "     10     \u001b[36m6405.5098\u001b[0m  0.0403\n",
            "     11     \u001b[36m5502.9313\u001b[0m  0.0355\n",
            "     12     \u001b[36m4687.3060\u001b[0m  0.0367\n",
            "     13     \u001b[36m3944.7731\u001b[0m  0.0368\n",
            "     14     \u001b[36m3263.5494\u001b[0m  0.0380\n",
            "     15     \u001b[36m2631.7707\u001b[0m  0.0337\n",
            "     16     \u001b[36m2037.1368\u001b[0m  0.0359\n",
            "     17     \u001b[36m1466.6373\u001b[0m  0.0354\n",
            "     18      \u001b[36m907.2860\u001b[0m  0.0327\n",
            "     19      \u001b[36m368.1899\u001b[0m  0.0328\n",
            "     20       \u001b[36m70.2289\u001b[0m  0.0353\n",
            "     21       \u001b[36m64.8930\u001b[0m  0.0341\n",
            "     22       \u001b[36m41.8885\u001b[0m  0.0349\n",
            "     23       \u001b[36m38.2927\u001b[0m  0.0312\n",
            "     24       \u001b[36m34.4355\u001b[0m  0.0336\n",
            "     25       \u001b[36m30.3832\u001b[0m  0.0336\n",
            "     26       \u001b[36m28.4991\u001b[0m  0.0344\n",
            "     27       \u001b[36m26.7977\u001b[0m  0.0324\n",
            "     28       27.0994  0.0349\n",
            "     29       \u001b[36m26.0353\u001b[0m  0.0330\n",
            "     30       \u001b[36m24.2245\u001b[0m  0.0338\n",
            "     31       \u001b[36m23.3312\u001b[0m  0.0345\n",
            "     32       \u001b[36m23.0972\u001b[0m  0.0350\n",
            "     33       \u001b[36m22.5642\u001b[0m  0.0351\n",
            "     34       \u001b[36m22.1781\u001b[0m  0.0338\n",
            "     35       \u001b[36m21.5842\u001b[0m  0.0341\n",
            "     36       \u001b[36m20.8131\u001b[0m  0.0330\n",
            "     37       \u001b[36m18.3121\u001b[0m  0.0341\n",
            "     38       \u001b[36m17.9060\u001b[0m  0.0352\n",
            "     39       18.7433  0.0321\n",
            "     40       18.8396  0.0308\n",
            "     41       18.2153  0.0322\n",
            "     42       \u001b[36m17.4934\u001b[0m  0.0316\n",
            "     43       \u001b[36m16.4742\u001b[0m  0.0322\n",
            "     44       \u001b[36m14.4951\u001b[0m  0.0341\n",
            "     45       14.7604  0.0341\n",
            "     46       15.1155  0.0347\n",
            "     47       14.9324  0.0342\n",
            "     48       \u001b[36m14.1507\u001b[0m  0.0308\n",
            "     49       \u001b[36m12.5069\u001b[0m  0.0334\n",
            "     50       12.8841  0.0332\n",
            "     51       12.7954  0.0332\n",
            "     52       \u001b[36m11.8821\u001b[0m  0.0345\n",
            "     53       \u001b[36m11.5444\u001b[0m  0.0331\n",
            "     54       \u001b[36m10.7724\u001b[0m  0.0332\n",
            "     55       \u001b[36m10.2200\u001b[0m  0.0336\n",
            "     56       \u001b[36m10.1223\u001b[0m  0.0316\n",
            "     57       10.8714  0.0312\n",
            "     58       10.6395  0.0342\n",
            "     59       10.7650  0.0324\n",
            "     60       10.6062  0.0331\n",
            "     61       10.6818  0.0329\n",
            "     62       10.3427  0.0340\n",
            "     63       10.4284  0.0330\n",
            "     64       \u001b[36m10.0218\u001b[0m  0.0307\n",
            "     65        \u001b[36m9.7487\u001b[0m  0.0308\n",
            "     66        \u001b[36m8.6892\u001b[0m  0.0342\n",
            "     67        9.1472  0.0351\n",
            "     68        9.1065  0.0381\n",
            "     69        9.1059  0.0335\n",
            "     70        9.0494  0.0321\n",
            "     71        9.1515  0.0331\n",
            "     72        8.8027  0.0322\n",
            "     73        8.7121  0.0321\n",
            "     74        \u001b[36m8.6770\u001b[0m  0.0301\n",
            "     75        \u001b[36m8.3432\u001b[0m  0.0346\n",
            "     76        \u001b[36m8.2820\u001b[0m  0.0309\n",
            "     77        \u001b[36m7.9510\u001b[0m  0.0326\n",
            "     78        8.1580  0.0333\n",
            "     79        \u001b[36m7.4409\u001b[0m  0.0327\n",
            "     80        7.6966  0.0312\n",
            "     81        7.7256  0.0336\n",
            "     82        \u001b[36m7.3098\u001b[0m  0.0317\n",
            "     83        7.3713  0.0332\n",
            "     84        \u001b[36m7.2281\u001b[0m  0.0339\n",
            "     85        \u001b[36m6.9955\u001b[0m  0.0301\n",
            "     86        \u001b[36m6.8027\u001b[0m  0.0320\n",
            "     87        7.0235  0.0327\n",
            "     88        \u001b[36m6.4012\u001b[0m  0.0311\n",
            "     89        \u001b[36m6.3424\u001b[0m  0.0323\n",
            "     90        \u001b[36m6.2059\u001b[0m  0.0334\n",
            "     91        6.2538  0.0332\n",
            "     92        6.4962  0.0311\n",
            "     93        \u001b[36m5.7343\u001b[0m  0.0327\n",
            "     94        6.1367  0.0327\n",
            "     95        5.7804  0.0331\n",
            "     96        5.9235  0.0338\n",
            "     97        \u001b[36m5.5161\u001b[0m  0.0327\n",
            "     98        5.6251  0.0331\n",
            "     99        5.5718  0.0311\n",
            "    100        \u001b[36m5.3986\u001b[0m  0.0348\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1     \u001b[36m3159.5045\u001b[0m  0.0221\n",
            "      2        \u001b[36m0.8183\u001b[0m  0.0210\n",
            "      3        \u001b[36m0.6970\u001b[0m  0.0240\n",
            "      4        \u001b[36m0.6965\u001b[0m  0.0222\n",
            "      5        \u001b[36m0.6960\u001b[0m  0.0217\n",
            "      6        \u001b[36m0.6956\u001b[0m  0.0224\n",
            "      7        \u001b[36m0.6951\u001b[0m  0.0245\n",
            "      8        \u001b[36m0.6946\u001b[0m  0.0222\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      9        \u001b[36m0.6942\u001b[0m  0.0220\n",
            "     10        \u001b[36m0.6937\u001b[0m  0.0226\n",
            "     11        \u001b[36m0.6933\u001b[0m  0.0228\n",
            "     12        \u001b[36m0.6928\u001b[0m  0.0236\n",
            "     13        \u001b[36m0.6924\u001b[0m  0.0221\n",
            "     14        \u001b[36m0.6920\u001b[0m  0.0200\n",
            "     15        \u001b[36m0.6916\u001b[0m  0.0216\n",
            "     16        \u001b[36m0.6912\u001b[0m  0.0211\n",
            "     17        \u001b[36m0.6907\u001b[0m  0.0239\n",
            "     18        \u001b[36m0.6903\u001b[0m  0.0241\n",
            "     19        \u001b[36m0.6900\u001b[0m  0.0226\n",
            "     20        \u001b[36m0.6896\u001b[0m  0.0226\n",
            "     21        \u001b[36m0.6892\u001b[0m  0.0241\n",
            "     22        \u001b[36m0.6888\u001b[0m  0.0244\n",
            "     23        \u001b[36m0.6884\u001b[0m  0.0211\n",
            "     24        \u001b[36m0.6881\u001b[0m  0.0223\n",
            "     25        \u001b[36m0.6877\u001b[0m  0.0230\n",
            "     26        \u001b[36m0.6873\u001b[0m  0.0222\n",
            "     27        \u001b[36m0.6870\u001b[0m  0.0197\n",
            "     28        \u001b[36m0.6866\u001b[0m  0.0220\n",
            "     29        \u001b[36m0.6863\u001b[0m  0.0225\n",
            "     30        \u001b[36m0.6859\u001b[0m  0.0216\n",
            "     31        \u001b[36m0.6856\u001b[0m  0.0216\n",
            "     32        \u001b[36m0.6853\u001b[0m  0.0221\n",
            "     33        \u001b[36m0.6850\u001b[0m  0.0206\n",
            "     34        \u001b[36m0.6846\u001b[0m  0.0230\n",
            "     35        \u001b[36m0.6843\u001b[0m  0.0211\n",
            "     36        \u001b[36m0.6840\u001b[0m  0.0221\n",
            "     37        \u001b[36m0.6837\u001b[0m  0.0220\n",
            "     38        \u001b[36m0.6834\u001b[0m  0.0224\n",
            "     39        \u001b[36m0.6831\u001b[0m  0.0222\n",
            "     40        \u001b[36m0.6828\u001b[0m  0.0225\n",
            "     41        \u001b[36m0.6825\u001b[0m  0.0231\n",
            "     42        \u001b[36m0.6822\u001b[0m  0.0231\n",
            "     43        \u001b[36m0.6819\u001b[0m  0.0247\n",
            "     44        \u001b[36m0.6817\u001b[0m  0.0215\n",
            "     45        \u001b[36m0.6814\u001b[0m  0.0224\n",
            "     46        \u001b[36m0.6811\u001b[0m  0.0239\n",
            "     47        \u001b[36m0.6808\u001b[0m  0.0211\n",
            "     48        \u001b[36m0.6806\u001b[0m  0.0237\n",
            "     49        \u001b[36m0.6803\u001b[0m  0.0221\n",
            "     50        \u001b[36m0.6801\u001b[0m  0.0241\n",
            "     51        \u001b[36m0.6798\u001b[0m  0.0210\n",
            "     52        \u001b[36m0.6796\u001b[0m  0.0220\n",
            "     53        \u001b[36m0.6793\u001b[0m  0.0215\n",
            "     54        \u001b[36m0.6791\u001b[0m  0.0221\n",
            "     55        \u001b[36m0.6788\u001b[0m  0.0216\n",
            "     56        \u001b[36m0.6786\u001b[0m  0.0221\n",
            "     57        \u001b[36m0.6784\u001b[0m  0.0216\n",
            "     58        \u001b[36m0.6781\u001b[0m  0.0220\n",
            "     59        \u001b[36m0.6779\u001b[0m  0.0234\n",
            "     60        \u001b[36m0.6777\u001b[0m  0.0230\n",
            "     61        \u001b[36m0.6775\u001b[0m  0.0226\n",
            "     62        \u001b[36m0.6772\u001b[0m  0.0220\n",
            "     63        \u001b[36m0.6770\u001b[0m  0.0202\n",
            "     64        \u001b[36m0.6768\u001b[0m  0.0210\n",
            "     65        \u001b[36m0.6766\u001b[0m  0.0227\n",
            "     66        \u001b[36m0.6764\u001b[0m  0.0242\n",
            "     67        \u001b[36m0.6762\u001b[0m  0.0237\n",
            "     68        \u001b[36m0.6760\u001b[0m  0.0241\n",
            "     69        \u001b[36m0.6758\u001b[0m  0.0241\n",
            "     70        \u001b[36m0.6756\u001b[0m  0.0222\n",
            "     71        \u001b[36m0.6754\u001b[0m  0.0246\n",
            "     72        \u001b[36m0.6752\u001b[0m  0.0231\n",
            "     73        \u001b[36m0.6750\u001b[0m  0.0226\n",
            "     74        \u001b[36m0.6749\u001b[0m  0.0231\n",
            "     75        \u001b[36m0.6747\u001b[0m  0.0226\n",
            "     76        \u001b[36m0.6745\u001b[0m  0.0233\n",
            "     77        \u001b[36m0.6743\u001b[0m  0.0221\n",
            "     78        \u001b[36m0.6742\u001b[0m  0.0226\n",
            "     79        \u001b[36m0.6740\u001b[0m  0.0231\n",
            "     80        \u001b[36m0.6738\u001b[0m  0.0216\n",
            "     81        \u001b[36m0.6736\u001b[0m  0.0233\n",
            "     82        \u001b[36m0.6735\u001b[0m  0.0220\n",
            "     83        \u001b[36m0.6733\u001b[0m  0.0231\n",
            "     84        \u001b[36m0.6732\u001b[0m  0.0233\n",
            "     85        \u001b[36m0.6730\u001b[0m  0.0250\n",
            "     86        \u001b[36m0.6728\u001b[0m  0.0227\n",
            "     87        \u001b[36m0.6727\u001b[0m  0.0211\n",
            "     88        \u001b[36m0.6725\u001b[0m  0.0247\n",
            "     89        \u001b[36m0.6724\u001b[0m  0.0241\n",
            "     90        \u001b[36m0.6722\u001b[0m  0.0224\n",
            "     91        \u001b[36m0.6721\u001b[0m  0.0226\n",
            "     92        \u001b[36m0.6719\u001b[0m  0.0217\n",
            "     93        \u001b[36m0.6718\u001b[0m  0.0202\n",
            "     94        \u001b[36m0.6717\u001b[0m  0.0211\n",
            "     95        \u001b[36m0.6715\u001b[0m  0.0230\n",
            "     96        \u001b[36m0.6714\u001b[0m  0.0220\n",
            "     97        \u001b[36m0.6713\u001b[0m  0.0232\n",
            "     98        \u001b[36m0.6711\u001b[0m  0.0231\n",
            "     99        \u001b[36m0.6710\u001b[0m  0.0246\n",
            "    100        \u001b[36m0.6709\u001b[0m  0.0221\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1     \u001b[36m3323.8657\u001b[0m  0.0206\n",
            "      2        \u001b[36m0.7311\u001b[0m  0.0201\n",
            "      3        \u001b[36m0.7243\u001b[0m  0.0216\n",
            "      4        \u001b[36m0.7234\u001b[0m  0.0225\n",
            "      5        \u001b[36m0.7224\u001b[0m  0.0220\n",
            "      6        \u001b[36m0.7215\u001b[0m  0.0221\n",
            "      7        \u001b[36m0.7206\u001b[0m  0.0236\n",
            "      8        \u001b[36m0.7197\u001b[0m  0.0232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      9        \u001b[36m0.7188\u001b[0m  0.0216\n",
            "     10        \u001b[36m0.7179\u001b[0m  0.0221\n",
            "     11        \u001b[36m0.7171\u001b[0m  0.0218\n",
            "     12        \u001b[36m0.7162\u001b[0m  0.0220\n",
            "     13        \u001b[36m0.7154\u001b[0m  0.0208\n",
            "     14        \u001b[36m0.7146\u001b[0m  0.0206\n",
            "     15        \u001b[36m0.7137\u001b[0m  0.0221\n",
            "     16        \u001b[36m0.7129\u001b[0m  0.0228\n",
            "     17        \u001b[36m0.7122\u001b[0m  0.0221\n",
            "     18        \u001b[36m0.7114\u001b[0m  0.0220\n",
            "     19        \u001b[36m0.7106\u001b[0m  0.0230\n",
            "     20        \u001b[36m0.7099\u001b[0m  0.0211\n",
            "     21        \u001b[36m0.7091\u001b[0m  0.0220\n",
            "     22        \u001b[36m0.7084\u001b[0m  0.0220\n",
            "     23        \u001b[36m0.7077\u001b[0m  0.0216\n",
            "     24        \u001b[36m0.7070\u001b[0m  0.0222\n",
            "     25        \u001b[36m0.7063\u001b[0m  0.0211\n",
            "     26        \u001b[36m0.7056\u001b[0m  0.0226\n",
            "     27        \u001b[36m0.7049\u001b[0m  0.0248\n",
            "     28        \u001b[36m0.7042\u001b[0m  0.0241\n",
            "     29        \u001b[36m0.7036\u001b[0m  0.0206\n",
            "     30        \u001b[36m0.7029\u001b[0m  0.0216\n",
            "     31        \u001b[36m0.7023\u001b[0m  0.0221\n",
            "     32        \u001b[36m0.7016\u001b[0m  0.0217\n",
            "     33        \u001b[36m0.7010\u001b[0m  0.0216\n",
            "     34        \u001b[36m0.7004\u001b[0m  0.0227\n",
            "     35        \u001b[36m0.6998\u001b[0m  0.0216\n",
            "     36        \u001b[36m0.6992\u001b[0m  0.0221\n",
            "     37        \u001b[36m0.6986\u001b[0m  0.0201\n",
            "     38        \u001b[36m0.6980\u001b[0m  0.0225\n",
            "     39        \u001b[36m0.6975\u001b[0m  0.0236\n",
            "     40        \u001b[36m0.6969\u001b[0m  0.0221\n",
            "     41        \u001b[36m0.6963\u001b[0m  0.0220\n",
            "     42        \u001b[36m0.6958\u001b[0m  0.0230\n",
            "     43        \u001b[36m0.6953\u001b[0m  0.0216\n",
            "     44        \u001b[36m0.6947\u001b[0m  0.0216\n",
            "     45        \u001b[36m0.6942\u001b[0m  0.0232\n",
            "     46        \u001b[36m0.6937\u001b[0m  0.0232\n",
            "     47        \u001b[36m0.6932\u001b[0m  0.0227\n",
            "     48        \u001b[36m0.6927\u001b[0m  0.0206\n",
            "     49        \u001b[36m0.6922\u001b[0m  0.0221\n",
            "     50        \u001b[36m0.6917\u001b[0m  0.0231\n",
            "     51        \u001b[36m0.6913\u001b[0m  0.0221\n",
            "     52        \u001b[36m0.6908\u001b[0m  0.0226\n",
            "     53        \u001b[36m0.6903\u001b[0m  0.0212\n",
            "     54        \u001b[36m0.6899\u001b[0m  0.0216\n",
            "     55        \u001b[36m0.6894\u001b[0m  0.0232\n",
            "     56        \u001b[36m0.6890\u001b[0m  0.0231\n",
            "     57        \u001b[36m0.6885\u001b[0m  0.0235\n",
            "     58        \u001b[36m0.6881\u001b[0m  0.0219\n",
            "     59        \u001b[36m0.6877\u001b[0m  0.0221\n",
            "     60        \u001b[36m0.6873\u001b[0m  0.0200\n",
            "     61        \u001b[36m0.6869\u001b[0m  0.0211\n",
            "     62        \u001b[36m0.6865\u001b[0m  0.0241\n",
            "     63        \u001b[36m0.6861\u001b[0m  0.0232\n",
            "     64        \u001b[36m0.6857\u001b[0m  0.0215\n",
            "     65        \u001b[36m0.6853\u001b[0m  0.0212\n",
            "     66        \u001b[36m0.6849\u001b[0m  0.0236\n",
            "     67        \u001b[36m0.6845\u001b[0m  0.0236\n",
            "     68        \u001b[36m0.6842\u001b[0m  0.0232\n",
            "     69        \u001b[36m0.6838\u001b[0m  0.0232\n",
            "     70        \u001b[36m0.6834\u001b[0m  0.0220\n",
            "     71        \u001b[36m0.6831\u001b[0m  0.0240\n",
            "     72        \u001b[36m0.6827\u001b[0m  0.0226\n",
            "     73        \u001b[36m0.6824\u001b[0m  0.0231\n",
            "     74        \u001b[36m0.6821\u001b[0m  0.0233\n",
            "     75        \u001b[36m0.6817\u001b[0m  0.0220\n",
            "     76        \u001b[36m0.6814\u001b[0m  0.0230\n",
            "     77        \u001b[36m0.6811\u001b[0m  0.0210\n",
            "     78        \u001b[36m0.6808\u001b[0m  0.0216\n",
            "     79        \u001b[36m0.6804\u001b[0m  0.0226\n",
            "     80        \u001b[36m0.6801\u001b[0m  0.0232\n",
            "     81        \u001b[36m0.6798\u001b[0m  0.0216\n",
            "     82        \u001b[36m0.6795\u001b[0m  0.0221\n",
            "     83        \u001b[36m0.6792\u001b[0m  0.0230\n",
            "     84        \u001b[36m0.6789\u001b[0m  0.0226\n",
            "     85        \u001b[36m0.6787\u001b[0m  0.0221\n",
            "     86        \u001b[36m0.6784\u001b[0m  0.0228\n",
            "     87        \u001b[36m0.6781\u001b[0m  0.0206\n",
            "     88        \u001b[36m0.6778\u001b[0m  0.0231\n",
            "     89        \u001b[36m0.6775\u001b[0m  0.0236\n",
            "     90        \u001b[36m0.6773\u001b[0m  0.0218\n",
            "     91        \u001b[36m0.6770\u001b[0m  0.0233\n",
            "     92        \u001b[36m0.6768\u001b[0m  0.0231\n",
            "     93        \u001b[36m0.6765\u001b[0m  0.0211\n",
            "     94        \u001b[36m0.6763\u001b[0m  0.0235\n",
            "     95        \u001b[36m0.6760\u001b[0m  0.0245\n",
            "     96        \u001b[36m0.6758\u001b[0m  0.0231\n",
            "     97        \u001b[36m0.6755\u001b[0m  0.0230\n",
            "     98        \u001b[36m0.6753\u001b[0m  0.0224\n",
            "     99        \u001b[36m0.6751\u001b[0m  0.0237\n",
            "    100        \u001b[36m0.6748\u001b[0m  0.0206\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m72743.7956\u001b[0m  0.0341\n",
            "      2    \u001b[36m63447.5648\u001b[0m  0.0334\n",
            "      3    \u001b[36m54938.0988\u001b[0m  0.0318\n",
            "      4    \u001b[36m47273.9101\u001b[0m  0.0356\n",
            "      5    \u001b[36m40394.8714\u001b[0m  0.0372\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6    \u001b[36m34179.8145\u001b[0m  0.0352\n",
            "      7    \u001b[36m28505.4649\u001b[0m  0.0321\n",
            "      8    \u001b[36m23266.5548\u001b[0m  0.0341\n",
            "      9    \u001b[36m18374.2068\u001b[0m  0.0327\n",
            "     10    \u001b[36m13746.7661\u001b[0m  0.0341\n",
            "     11     \u001b[36m9300.1456\u001b[0m  0.0316\n",
            "     12     \u001b[36m4939.4480\u001b[0m  0.0337\n",
            "     13     \u001b[36m1247.1757\u001b[0m  0.0344\n",
            "     14      \u001b[36m178.5844\u001b[0m  0.0321\n",
            "     15      191.0514  0.0329\n",
            "     16      261.4456  0.0337\n",
            "     17      239.5682  0.0336\n",
            "     18      236.6767  0.0341\n",
            "     19      238.6057  0.0306\n",
            "     20      230.9263  0.0336\n",
            "     21      223.7866  0.0322\n",
            "     22      220.1303  0.0311\n",
            "     23      216.8508  0.0337\n",
            "     24      204.7688  0.0401\n",
            "     25      190.7912  0.0330\n",
            "     26      207.1829  0.0345\n",
            "     27      196.0347  0.0349\n",
            "     28      195.7878  0.0336\n",
            "     29      194.2897  0.0337\n",
            "     30      190.3566  0.0336\n",
            "     31      182.2654  0.0353\n",
            "     32      187.3828  0.0351\n",
            "     33      188.6760  0.0338\n",
            "     34      178.7014  0.0321\n",
            "     35      \u001b[36m164.6644\u001b[0m  0.0331\n",
            "     36      \u001b[36m160.9705\u001b[0m  0.0326\n",
            "     37      \u001b[36m152.0522\u001b[0m  0.0321\n",
            "     38      \u001b[36m143.7748\u001b[0m  0.0341\n",
            "     39      144.6420  0.0327\n",
            "     40      145.6018  0.0341\n",
            "     41      144.0644  0.0310\n",
            "     42      151.3366  0.0325\n",
            "     43      153.9591  0.0337\n",
            "     44      149.5218  0.0323\n",
            "     45      154.6697  0.0346\n",
            "     46      156.0194  0.0321\n",
            "     47      158.6926  0.0326\n",
            "     48      154.4414  0.0345\n",
            "     49      158.2571  0.0331\n",
            "     50      145.3181  0.0327\n",
            "     51      145.0467  0.0336\n",
            "     52      165.2337  0.0318\n",
            "     53      170.5783  0.0327\n",
            "     54      145.2369  0.0327\n",
            "     55      \u001b[36m142.1606\u001b[0m  0.0319\n",
            "     56      148.2691  0.0332\n",
            "     57      148.5154  0.0316\n",
            "     58      159.7947  0.0333\n",
            "     59      154.5143  0.0321\n",
            "     60      158.3319  0.0311\n",
            "     61      146.3436  0.0303\n",
            "     62      146.6546  0.0335\n",
            "     63      160.3820  0.0326\n",
            "     64      \u001b[36m138.8353\u001b[0m  0.0306\n",
            "     65      \u001b[36m134.9563\u001b[0m  0.0332\n",
            "     66      144.9781  0.0316\n",
            "     67      162.2068  0.0316\n",
            "     68      169.3875  0.0351\n",
            "     69      137.9663  0.0306\n",
            "     70      137.7611  0.0321\n",
            "     71      144.2557  0.0337\n",
            "     72      146.6208  0.0316\n",
            "     73      144.5262  0.0325\n",
            "     74      140.6921  0.0320\n",
            "     75      142.4697  0.0336\n",
            "     76      150.5374  0.0321\n",
            "     77      148.2581  0.0342\n",
            "     78      \u001b[36m127.0868\u001b[0m  0.0353\n",
            "     79      \u001b[36m102.2407\u001b[0m  0.0321\n",
            "     80       \u001b[36m91.6557\u001b[0m  0.0300\n",
            "     81       \u001b[36m85.1493\u001b[0m  0.0326\n",
            "     82       \u001b[36m78.3944\u001b[0m  0.0339\n",
            "     83       80.9122  0.0321\n",
            "     84       80.0317  0.0462\n",
            "     85       81.0352  0.0397\n",
            "     86       \u001b[36m72.0550\u001b[0m  0.0381\n",
            "     87       \u001b[36m60.5611\u001b[0m  0.0342\n",
            "     88       \u001b[36m56.7914\u001b[0m  0.0301\n",
            "     89       \u001b[36m39.5687\u001b[0m  0.0326\n",
            "     90       \u001b[36m32.5184\u001b[0m  0.0320\n",
            "     91       \u001b[36m30.3633\u001b[0m  0.0317\n",
            "     92       32.1319  0.0333\n",
            "     93       \u001b[36m27.4064\u001b[0m  0.0326\n",
            "     94       30.4984  0.0315\n",
            "     95       \u001b[36m24.6053\u001b[0m  0.0323\n",
            "     96       26.3187  0.0322\n",
            "     97       \u001b[36m20.9161\u001b[0m  0.0330\n",
            "     98       24.2162  0.0310\n",
            "     99       23.3803  0.0320\n",
            "    100       23.5799  0.0335\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m83538.3406\u001b[0m  0.0316\n",
            "      2    \u001b[36m73867.2179\u001b[0m  0.0326\n",
            "      3    \u001b[36m65350.4675\u001b[0m  0.0326\n",
            "      4    \u001b[36m57591.1615\u001b[0m  0.0319\n",
            "      5    \u001b[36m50579.8104\u001b[0m  0.0332\n",
            "      6    \u001b[36m44267.9954\u001b[0m  0.0316"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      7    \u001b[36m38596.0505\u001b[0m  0.0350\n",
            "      8    \u001b[36m33501.1263\u001b[0m  0.0308\n",
            "      9    \u001b[36m28921.3997\u001b[0m  0.0327\n",
            "     10    \u001b[36m24799.2336\u001b[0m  0.0311\n",
            "     11    \u001b[36m21079.1082\u001b[0m  0.0307\n",
            "     12    \u001b[36m17714.4094\u001b[0m  0.0322\n",
            "     13    \u001b[36m14659.1855\u001b[0m  0.0314\n",
            "     14    \u001b[36m11855.1441\u001b[0m  0.0328\n",
            "     15     \u001b[36m9243.7297\u001b[0m  0.0321\n",
            "     16     \u001b[36m6774.6108\u001b[0m  0.0326\n",
            "     17     \u001b[36m4394.2052\u001b[0m  0.0332\n",
            "     18     \u001b[36m2069.4897\u001b[0m  0.0336\n",
            "     19      \u001b[36m403.7687\u001b[0m  0.0316\n",
            "     20      \u001b[36m196.6150\u001b[0m  0.0333\n",
            "     21      207.4304  0.0331\n",
            "     22      \u001b[36m195.5365\u001b[0m  0.0306\n",
            "     23      \u001b[36m190.5083\u001b[0m  0.0331\n",
            "     24      \u001b[36m182.9861\u001b[0m  0.0332\n",
            "     25      \u001b[36m175.7252\u001b[0m  0.0333\n",
            "     26      \u001b[36m167.1133\u001b[0m  0.0301\n",
            "     27      \u001b[36m157.1833\u001b[0m  0.0325\n",
            "     28      \u001b[36m146.7859\u001b[0m  0.0326\n",
            "     29      \u001b[36m142.2308\u001b[0m  0.0318\n",
            "     30      \u001b[36m141.3955\u001b[0m  0.0297\n",
            "     31      \u001b[36m138.5383\u001b[0m  0.0342\n",
            "     32      \u001b[36m129.9394\u001b[0m  0.0300\n",
            "     33      133.7369  0.0306\n",
            "     34      \u001b[36m127.3912\u001b[0m  0.0325\n",
            "     35      \u001b[36m123.2666\u001b[0m  0.0311\n",
            "     36      \u001b[36m122.0749\u001b[0m  0.0345\n",
            "     37      \u001b[36m116.1076\u001b[0m  0.0321\n",
            "     38      \u001b[36m114.7283\u001b[0m  0.0327\n",
            "     39      116.3491  0.0346\n",
            "     40      \u001b[36m113.6417\u001b[0m  0.0320\n",
            "     41      \u001b[36m107.7182\u001b[0m  0.0306\n",
            "     42      \u001b[36m103.8260\u001b[0m  0.0323\n",
            "     43      \u001b[36m100.5812\u001b[0m  0.0307\n",
            "     44       \u001b[36m94.1332\u001b[0m  0.0322\n",
            "     45       \u001b[36m88.9672\u001b[0m  0.0316\n",
            "     46       \u001b[36m83.7419\u001b[0m  0.0326\n",
            "     47       84.1652  0.0317\n",
            "     48       89.1811  0.0307\n",
            "     49       93.7494  0.0305\n",
            "     50       91.6329  0.0299\n",
            "     51       86.3787  0.0322\n",
            "     52       87.9202  0.0336\n",
            "     53       86.7282  0.0323\n",
            "     54       86.1498  0.0321\n",
            "     55       86.7065  0.0287\n",
            "     56       87.2158  0.0323\n",
            "     57       85.1944  0.0321\n",
            "     58       84.8586  0.0330\n",
            "     59       85.9319  0.0321\n",
            "     60       \u001b[36m81.0689\u001b[0m  0.0317\n",
            "     61       \u001b[36m79.8514\u001b[0m  0.0307\n",
            "     62       \u001b[36m76.5693\u001b[0m  0.0328\n",
            "     63       76.9155  0.0317\n",
            "     64       \u001b[36m74.5257\u001b[0m  0.0320\n",
            "     65       74.9028  0.0316\n",
            "     66       \u001b[36m72.6869\u001b[0m  0.0322\n",
            "     67       74.3501  0.0298\n",
            "     68       \u001b[36m70.4700\u001b[0m  0.0336\n",
            "     69       87.4591  0.0309\n",
            "     70       84.8972  0.0341\n",
            "     71       78.8821  0.0331\n",
            "     72       79.6267  0.0321\n",
            "     73       78.5672  0.0321\n",
            "     74       71.6388  0.0306\n",
            "     75       71.1071  0.0334\n",
            "     76       70.9424  0.0332\n",
            "     77       70.4883  0.0317\n",
            "     78       \u001b[36m70.3327\u001b[0m  0.0316\n",
            "     79       \u001b[36m64.0737\u001b[0m  0.0317\n",
            "     80       \u001b[36m53.6898\u001b[0m  0.0294\n",
            "     81       \u001b[36m45.1425\u001b[0m  0.0336\n",
            "     82       \u001b[36m33.1889\u001b[0m  0.0322\n",
            "     83       \u001b[36m27.2172\u001b[0m  0.0326\n",
            "     84       \u001b[36m23.1537\u001b[0m  0.0307\n",
            "     85       \u001b[36m17.9170\u001b[0m  0.0322\n",
            "     86       \u001b[36m13.5269\u001b[0m  0.0326\n",
            "     87       \u001b[36m11.4640\u001b[0m  0.0334\n",
            "     88       12.6049  0.0346\n",
            "     89       12.0543  0.0322\n",
            "     90       \u001b[36m10.2767\u001b[0m  0.0317\n",
            "     91       12.6438  0.0336\n",
            "     92       10.5551  0.0321\n",
            "     93       11.7257  0.0311\n",
            "     94       10.5314  0.0313\n",
            "     95       11.4705  0.0311\n",
            "     96       16.4325  0.0327\n",
            "     97        \u001b[36m7.6747\u001b[0m  0.0331\n",
            "     98        9.8966  0.0342\n",
            "     99       14.3222  0.0332\n",
            "    100        9.6022  0.0338\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1     \u001b[36m9364.0249\u001b[0m  0.0226\n",
            "      2        \u001b[36m0.6723\u001b[0m  0.0212\n",
            "      3        \u001b[36m0.6721\u001b[0m  0.0236\n",
            "      4        \u001b[36m0.6720\u001b[0m  0.0261\n",
            "      5        \u001b[36m0.6718\u001b[0m  0.0226\n",
            "      6        \u001b[36m0.6717\u001b[0m  0.0210\n",
            "      7        \u001b[36m0.6716\u001b[0m  0.0220\n",
            "      8        \u001b[36m0.6714\u001b[0m  0.0220"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      9        \u001b[36m0.6713\u001b[0m  0.0228\n",
            "     10        \u001b[36m0.6711\u001b[0m  0.0225\n",
            "     11        \u001b[36m0.6710\u001b[0m  0.0231\n",
            "     12        \u001b[36m0.6709\u001b[0m  0.0214\n",
            "     13        \u001b[36m0.6708\u001b[0m  0.0207\n",
            "     14        \u001b[36m0.6706\u001b[0m  0.0216\n",
            "     15        \u001b[36m0.6705\u001b[0m  0.0221\n",
            "     16        \u001b[36m0.6704\u001b[0m  0.0211\n",
            "     17        \u001b[36m0.6703\u001b[0m  0.0231\n",
            "     18        \u001b[36m0.6701\u001b[0m  0.0231\n",
            "     19        \u001b[36m0.6700\u001b[0m  0.0222\n",
            "     20        \u001b[36m0.6699\u001b[0m  0.0211\n",
            "     21        \u001b[36m0.6698\u001b[0m  0.0210\n",
            "     22        \u001b[36m0.6697\u001b[0m  0.0222\n",
            "     23        \u001b[36m0.6696\u001b[0m  0.0220\n",
            "     24        \u001b[36m0.6695\u001b[0m  0.0220\n",
            "     25        \u001b[36m0.6694\u001b[0m  0.0225\n",
            "     26        \u001b[36m0.6692\u001b[0m  0.0230\n",
            "     27        \u001b[36m0.6691\u001b[0m  0.0217\n",
            "     28        \u001b[36m0.6690\u001b[0m  0.0212\n",
            "     29        \u001b[36m0.6689\u001b[0m  0.0211\n",
            "     30        \u001b[36m0.6688\u001b[0m  0.0221\n",
            "     31        \u001b[36m0.6687\u001b[0m  0.0196\n",
            "     32        \u001b[36m0.6686\u001b[0m  0.0218\n",
            "     33        \u001b[36m0.6685\u001b[0m  0.0230\n",
            "     34        \u001b[36m0.6684\u001b[0m  0.0210\n",
            "     35        \u001b[36m0.6683\u001b[0m  0.0226\n",
            "     36        \u001b[36m0.6683\u001b[0m  0.0221\n",
            "     37        \u001b[36m0.6682\u001b[0m  0.0226\n",
            "     38        \u001b[36m0.6681\u001b[0m  0.0206\n",
            "     39        \u001b[36m0.6680\u001b[0m  0.0226\n",
            "     40        \u001b[36m0.6679\u001b[0m  0.0216\n",
            "     41        \u001b[36m0.6678\u001b[0m  0.0201\n",
            "     42        \u001b[36m0.6677\u001b[0m  0.0222\n",
            "     43        \u001b[36m0.6676\u001b[0m  0.0231\n",
            "     44        \u001b[36m0.6675\u001b[0m  0.0199\n",
            "     45        \u001b[36m0.6675\u001b[0m  0.0205\n",
            "     46        \u001b[36m0.6674\u001b[0m  0.0241\n",
            "     47        \u001b[36m0.6673\u001b[0m  0.0237\n",
            "     48        \u001b[36m0.6672\u001b[0m  0.0206\n",
            "     49        \u001b[36m0.6671\u001b[0m  0.0217\n",
            "     50        \u001b[36m0.6671\u001b[0m  0.0221\n",
            "     51        \u001b[36m0.6670\u001b[0m  0.0211\n",
            "     52        \u001b[36m0.6669\u001b[0m  0.0226\n",
            "     53        \u001b[36m0.6668\u001b[0m  0.0226\n",
            "     54        \u001b[36m0.6668\u001b[0m  0.0221\n",
            "     55        \u001b[36m0.6667\u001b[0m  0.0241\n",
            "     56        \u001b[36m0.6666\u001b[0m  0.0216\n",
            "     57        \u001b[36m0.6665\u001b[0m  0.0461\n",
            "     58        \u001b[36m0.6665\u001b[0m  0.0240\n",
            "     59        \u001b[36m0.6664\u001b[0m  0.0231\n",
            "     60        \u001b[36m0.6663\u001b[0m  0.0223\n",
            "     61        \u001b[36m0.6663\u001b[0m  0.0221\n",
            "     62        \u001b[36m0.6662\u001b[0m  0.0228\n",
            "     63        \u001b[36m0.6661\u001b[0m  0.0196\n",
            "     64        \u001b[36m0.6661\u001b[0m  0.0212\n",
            "     65        \u001b[36m0.6660\u001b[0m  0.0221\n",
            "     66        \u001b[36m0.6660\u001b[0m  0.0225\n",
            "     67        \u001b[36m0.6659\u001b[0m  0.0216\n",
            "     68        \u001b[36m0.6658\u001b[0m  0.0226\n",
            "     69        \u001b[36m0.6658\u001b[0m  0.0221\n",
            "     70        \u001b[36m0.6657\u001b[0m  0.0221\n",
            "     71        \u001b[36m0.6656\u001b[0m  0.0199\n",
            "     72        \u001b[36m0.6656\u001b[0m  0.0201\n",
            "     73        \u001b[36m0.6655\u001b[0m  0.0222\n",
            "     74        \u001b[36m0.6655\u001b[0m  0.0225\n",
            "     75        \u001b[36m0.6654\u001b[0m  0.0220\n",
            "     76        \u001b[36m0.6654\u001b[0m  0.0220\n",
            "     77        \u001b[36m0.6653\u001b[0m  0.0226\n",
            "     78        \u001b[36m0.6653\u001b[0m  0.0236\n",
            "     79        \u001b[36m0.6652\u001b[0m  0.0198\n",
            "     80        \u001b[36m0.6652\u001b[0m  0.0216\n",
            "     81        \u001b[36m0.6651\u001b[0m  0.0221\n",
            "     82        \u001b[36m0.6650\u001b[0m  0.0220\n",
            "     83        \u001b[36m0.6650\u001b[0m  0.0230\n",
            "     84        \u001b[36m0.6649\u001b[0m  0.0242\n",
            "     85        \u001b[36m0.6649\u001b[0m  0.0226\n",
            "     86        \u001b[36m0.6649\u001b[0m  0.0221\n",
            "     87        \u001b[36m0.6648\u001b[0m  0.0200\n",
            "     88        \u001b[36m0.6648\u001b[0m  0.0236\n",
            "     89        \u001b[36m0.6647\u001b[0m  0.0246\n",
            "     90        \u001b[36m0.6647\u001b[0m  0.0236\n",
            "     91        \u001b[36m0.6646\u001b[0m  0.0231\n",
            "     92        \u001b[36m0.6646\u001b[0m  0.0231\n",
            "     93        \u001b[36m0.6645\u001b[0m  0.0220\n",
            "     94        \u001b[36m0.6645\u001b[0m  0.0216\n",
            "     95        \u001b[36m0.6644\u001b[0m  0.0220\n",
            "     96        \u001b[36m0.6644\u001b[0m  0.0220\n",
            "     97        \u001b[36m0.6644\u001b[0m  0.0232\n",
            "     98        \u001b[36m0.6643\u001b[0m  0.0215\n",
            "     99        \u001b[36m0.6643\u001b[0m  0.0231\n",
            "    100        \u001b[36m0.6642\u001b[0m  0.0230\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m24010.5552\u001b[0m  0.0231\n",
            "      2      \u001b[36m195.9739\u001b[0m  0.0226\n",
            "      3        \u001b[36m0.7200\u001b[0m  0.0244\n",
            "      4        \u001b[36m0.7191\u001b[0m  0.0226\n",
            "      5        \u001b[36m0.7182\u001b[0m  0.0200\n",
            "      6        \u001b[36m0.7174\u001b[0m  0.0231\n",
            "      7        \u001b[36m0.7165\u001b[0m  0.0201\n",
            "      8        \u001b[36m0.7157\u001b[0m  0.0220\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      9        \u001b[36m0.7149\u001b[0m  0.0222\n",
            "     10        \u001b[36m0.7140\u001b[0m  0.0231\n",
            "     11        \u001b[36m0.7132\u001b[0m  0.0221\n",
            "     12        \u001b[36m0.7124\u001b[0m  0.0216\n",
            "     13        \u001b[36m0.7117\u001b[0m  0.0220\n",
            "     14        \u001b[36m0.7109\u001b[0m  0.0241\n",
            "     15        \u001b[36m0.7101\u001b[0m  0.0216\n",
            "     16        \u001b[36m0.7094\u001b[0m  0.0197\n",
            "     17        \u001b[36m0.7086\u001b[0m  0.0201\n",
            "     18        \u001b[36m0.7079\u001b[0m  0.0230\n",
            "     19        \u001b[36m0.7072\u001b[0m  0.0239\n",
            "     20        \u001b[36m0.7065\u001b[0m  0.0222\n",
            "     21        \u001b[36m0.7058\u001b[0m  0.0210\n",
            "     22        \u001b[36m0.7051\u001b[0m  0.0221\n",
            "     23        \u001b[36m0.7044\u001b[0m  0.0206\n",
            "     24        \u001b[36m0.7038\u001b[0m  0.0201\n",
            "     25        \u001b[36m0.7031\u001b[0m  0.0226\n",
            "     26        \u001b[36m0.7025\u001b[0m  0.0224\n",
            "     27        \u001b[36m0.7019\u001b[0m  0.0202\n",
            "     28        \u001b[36m0.7012\u001b[0m  0.0228\n",
            "     29        \u001b[36m0.7006\u001b[0m  0.0211\n",
            "     30        \u001b[36m0.7000\u001b[0m  0.0222\n",
            "     31        \u001b[36m0.6994\u001b[0m  0.0221\n",
            "     32        \u001b[36m0.6988\u001b[0m  0.0226\n",
            "     33        \u001b[36m0.6982\u001b[0m  0.0211\n",
            "     34        \u001b[36m0.6977\u001b[0m  0.0230\n",
            "     35        \u001b[36m0.6971\u001b[0m  0.0221\n",
            "     36        \u001b[36m0.6965\u001b[0m  0.0212\n",
            "     37        \u001b[36m0.6960\u001b[0m  0.0213\n",
            "     38        \u001b[36m0.6955\u001b[0m  0.0216\n",
            "     39        \u001b[36m0.6949\u001b[0m  0.0216\n",
            "     40        \u001b[36m0.6944\u001b[0m  0.0225\n",
            "     41        \u001b[36m0.6939\u001b[0m  0.0216\n",
            "     42        \u001b[36m0.6934\u001b[0m  0.0230\n",
            "     43        \u001b[36m0.6929\u001b[0m  0.0236\n",
            "     44        \u001b[36m0.6924\u001b[0m  0.0226\n",
            "     45        \u001b[36m0.6919\u001b[0m  0.0228\n",
            "     46        \u001b[36m0.6914\u001b[0m  0.0200\n",
            "     47        \u001b[36m0.6909\u001b[0m  0.0231\n",
            "     48        \u001b[36m0.6905\u001b[0m  0.0200\n",
            "     49        \u001b[36m0.6900\u001b[0m  0.0206\n",
            "     50        \u001b[36m0.6896\u001b[0m  0.0200\n",
            "     51        \u001b[36m0.6891\u001b[0m  0.0222\n",
            "     52        \u001b[36m0.6887\u001b[0m  0.0231\n",
            "     53        \u001b[36m0.6883\u001b[0m  0.0216\n",
            "     54        \u001b[36m0.6878\u001b[0m  0.0223\n",
            "     55        \u001b[36m0.6874\u001b[0m  0.0222\n",
            "     56        \u001b[36m0.6870\u001b[0m  0.0216\n",
            "     57        \u001b[36m0.6866\u001b[0m  0.0231\n",
            "     58        \u001b[36m0.6862\u001b[0m  0.0211\n",
            "     59        \u001b[36m0.6858\u001b[0m  0.0224\n",
            "     60        \u001b[36m0.6854\u001b[0m  0.0221\n",
            "     61        \u001b[36m0.6850\u001b[0m  0.0250\n",
            "     62        \u001b[36m0.6847\u001b[0m  0.0246\n",
            "     63        \u001b[36m0.6843\u001b[0m  0.0271\n",
            "     64        \u001b[36m0.6839\u001b[0m  0.0252\n",
            "     65        \u001b[36m0.6836\u001b[0m  0.0267\n",
            "     66        \u001b[36m0.6832\u001b[0m  0.0248\n",
            "     67        \u001b[36m0.6829\u001b[0m  0.0234\n",
            "     68        \u001b[36m0.6825\u001b[0m  0.0227\n",
            "     69        \u001b[36m0.6822\u001b[0m  0.0221\n",
            "     70        \u001b[36m0.6818\u001b[0m  0.0226\n",
            "     71        \u001b[36m0.6815\u001b[0m  0.0231\n",
            "     72        \u001b[36m0.6812\u001b[0m  0.0221\n",
            "     73        \u001b[36m0.6809\u001b[0m  0.0247\n",
            "     74        \u001b[36m0.6805\u001b[0m  0.0216\n",
            "     75        \u001b[36m0.6802\u001b[0m  0.0256\n",
            "     76        \u001b[36m0.6799\u001b[0m  0.0244\n",
            "     77        \u001b[36m0.6796\u001b[0m  0.0231\n",
            "     78        \u001b[36m0.6793\u001b[0m  0.0225\n",
            "     79        \u001b[36m0.6790\u001b[0m  0.0236\n",
            "     80        \u001b[36m0.6788\u001b[0m  0.0216\n",
            "     81        \u001b[36m0.6785\u001b[0m  0.0216\n",
            "     82        \u001b[36m0.6782\u001b[0m  0.0222\n",
            "     83        \u001b[36m0.6779\u001b[0m  0.0211\n",
            "     84        \u001b[36m0.6776\u001b[0m  0.0219\n",
            "     85        \u001b[36m0.6774\u001b[0m  0.0220\n",
            "     86        \u001b[36m0.6771\u001b[0m  0.0222\n",
            "     87        \u001b[36m0.6769\u001b[0m  0.0215\n",
            "     88        \u001b[36m0.6766\u001b[0m  0.0230\n",
            "     89        \u001b[36m0.6763\u001b[0m  0.0227\n",
            "     90        \u001b[36m0.6761\u001b[0m  0.0221\n",
            "     91        \u001b[36m0.6759\u001b[0m  0.0206\n",
            "     92        \u001b[36m0.6756\u001b[0m  0.0216\n",
            "     93        \u001b[36m0.6754\u001b[0m  0.0226\n",
            "     94        \u001b[36m0.6751\u001b[0m  0.0216\n",
            "     95        \u001b[36m0.6749\u001b[0m  0.0216\n",
            "     96        \u001b[36m0.6747\u001b[0m  0.0213\n",
            "     97        \u001b[36m0.6745\u001b[0m  0.0235\n",
            "     98        \u001b[36m0.6742\u001b[0m  0.0236\n",
            "     99        \u001b[36m0.6740\u001b[0m  0.0211\n",
            "    100        \u001b[36m0.6738\u001b[0m  0.0225\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.9235\u001b[0m  0.0351\n",
            "      2        \u001b[36m1.8575\u001b[0m  0.0327\n",
            "      3        \u001b[36m1.7890\u001b[0m  0.0461\n",
            "      4        \u001b[36m1.7189\u001b[0m  0.0377\n",
            "      5        \u001b[36m1.6472\u001b[0m  0.0339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m1.5726\u001b[0m  0.0311\n",
            "      7        \u001b[36m1.4901\u001b[0m  0.0333\n",
            "      8        \u001b[36m1.3849\u001b[0m  0.0336\n",
            "      9        \u001b[36m1.2230\u001b[0m  0.0323\n",
            "     10        \u001b[36m0.9781\u001b[0m  0.0306\n",
            "     11        \u001b[36m0.7669\u001b[0m  0.0306\n",
            "     12        \u001b[36m0.6936\u001b[0m  0.0322\n",
            "     13        \u001b[36m0.6770\u001b[0m  0.0320\n",
            "     14        \u001b[36m0.6739\u001b[0m  0.0306\n",
            "     15        \u001b[36m0.6731\u001b[0m  0.0336\n",
            "     16        \u001b[36m0.6724\u001b[0m  0.0327\n",
            "     17        \u001b[36m0.6719\u001b[0m  0.0331\n",
            "     18        \u001b[36m0.6715\u001b[0m  0.0316\n",
            "     19        \u001b[36m0.6712\u001b[0m  0.0302\n",
            "     20        \u001b[36m0.6709\u001b[0m  0.0327\n",
            "     21        \u001b[36m0.6707\u001b[0m  0.0341\n",
            "     22        \u001b[36m0.6705\u001b[0m  0.0311\n",
            "     23        \u001b[36m0.6704\u001b[0m  0.0321\n",
            "     24        \u001b[36m0.6702\u001b[0m  0.0312\n",
            "     25        \u001b[36m0.6701\u001b[0m  0.0321\n",
            "     26        \u001b[36m0.6700\u001b[0m  0.0311\n",
            "     27        \u001b[36m0.6699\u001b[0m  0.0322\n",
            "     28        \u001b[36m0.6698\u001b[0m  0.0312\n",
            "     29        \u001b[36m0.6697\u001b[0m  0.0311\n",
            "     30        \u001b[36m0.6697\u001b[0m  0.0335\n",
            "     31        \u001b[36m0.6696\u001b[0m  0.0357\n",
            "     32        \u001b[36m0.6695\u001b[0m  0.0326\n",
            "     33        \u001b[36m0.6695\u001b[0m  0.0353\n",
            "     34        \u001b[36m0.6694\u001b[0m  0.0337\n",
            "     35        \u001b[36m0.6694\u001b[0m  0.0323\n",
            "     36        \u001b[36m0.6693\u001b[0m  0.0327\n",
            "     37        \u001b[36m0.6693\u001b[0m  0.0356\n",
            "     38        \u001b[36m0.6692\u001b[0m  0.0337\n",
            "     39        \u001b[36m0.6692\u001b[0m  0.0320\n",
            "     40        \u001b[36m0.6691\u001b[0m  0.0321\n",
            "     41        \u001b[36m0.6691\u001b[0m  0.0333\n",
            "     42        \u001b[36m0.6691\u001b[0m  0.0318\n",
            "     43        \u001b[36m0.6690\u001b[0m  0.0336\n",
            "     44        \u001b[36m0.6439\u001b[0m  0.0337\n",
            "     45        0.6944  0.0322\n",
            "     46        0.6801  0.0322\n",
            "     47        0.6731  0.0341\n",
            "     48        0.6701  0.0352\n",
            "     49        0.6688  0.0321\n",
            "     50        0.6601  0.0336\n",
            "     51        0.6631  0.0354\n",
            "     52        0.6620  0.0320\n",
            "     53        0.6619  0.0321\n",
            "     54        0.6618  0.0319\n",
            "     55        0.6617  0.0303\n",
            "     56        0.6617  0.0306\n",
            "     57        0.6617  0.0323\n",
            "     58        0.6616  0.0351\n",
            "     59        0.6616  0.0320\n",
            "     60        0.6616  0.0327\n",
            "     61        0.6615  0.0336\n",
            "     62        0.6615  0.0306\n",
            "     63        0.6615  0.0307\n",
            "     64        0.6615  0.0302\n",
            "     65        0.6614  0.0322\n",
            "     66        0.6614  0.0314\n",
            "     67        0.6614  0.0307\n",
            "     68        0.6613  0.0321\n",
            "     69        0.6613  0.0305\n",
            "     70        0.6613  0.0331\n",
            "     71        0.6613  0.0323\n",
            "     72        0.6612  0.0308\n",
            "     73        0.6612  0.0317\n",
            "     74        0.6612  0.0298\n",
            "     75        0.6611  0.0297\n",
            "     76        0.6611  0.0347\n",
            "     77        0.6611  0.0316\n",
            "     78        0.6611  0.0316\n",
            "     79        0.6610  0.0352\n",
            "     80        0.6610  0.0311\n",
            "     81        0.6610  0.0332\n",
            "     82        0.6609  0.0331\n",
            "     83        0.6609  0.0327\n",
            "     84        0.6609  0.0318\n",
            "     85        0.6609  0.0330\n",
            "     86        0.6608  0.0306\n",
            "     87        0.6608  0.0321\n",
            "     88        0.6608  0.0312\n",
            "     89        0.6608  0.0307\n",
            "     90        0.6607  0.0331\n",
            "     91        0.6607  0.0362\n",
            "     92        0.6607  0.0379\n",
            "     93        0.6607  0.0371\n",
            "     94        0.6606  0.0317\n",
            "     95        0.6606  0.0331\n",
            "     96        0.6606  0.0323\n",
            "     97        0.6606  0.0348\n",
            "     98        0.6605  0.0321\n",
            "     99        0.6605  0.0305\n",
            "    100        0.6605  0.0302\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.5530\u001b[0m  0.0348\n",
            "      2        \u001b[36m1.4868\u001b[0m  0.0319\n",
            "      3        \u001b[36m1.4217\u001b[0m  0.0337\n",
            "      4        \u001b[36m1.3549\u001b[0m  0.0306\n",
            "      5        \u001b[36m1.2859\u001b[0m  0.0312\n",
            "      6        \u001b[36m1.2117\u001b[0m  0.0341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      7        \u001b[36m1.1254\u001b[0m  0.0327\n",
            "      8        \u001b[36m1.0169\u001b[0m  0.0318\n",
            "      9        \u001b[36m0.8868\u001b[0m  0.0333\n",
            "     10        \u001b[36m0.7715\u001b[0m  0.0342\n",
            "     11        \u001b[36m0.7064\u001b[0m  0.0311\n",
            "     12        \u001b[36m0.6806\u001b[0m  0.0336\n",
            "     13        \u001b[36m0.6718\u001b[0m  0.0312\n",
            "     14        \u001b[36m0.6686\u001b[0m  0.0328\n",
            "     15        \u001b[36m0.6674\u001b[0m  0.0340\n",
            "     16        \u001b[36m0.6667\u001b[0m  0.0321\n",
            "     17        \u001b[36m0.6664\u001b[0m  0.0321\n",
            "     18        \u001b[36m0.6661\u001b[0m  0.0337\n",
            "     19        \u001b[36m0.6660\u001b[0m  0.0313\n",
            "     20        \u001b[36m0.6658\u001b[0m  0.0308\n",
            "     21        \u001b[36m0.6657\u001b[0m  0.0331\n",
            "     22        \u001b[36m0.6656\u001b[0m  0.0336\n",
            "     23        \u001b[36m0.6656\u001b[0m  0.0331\n",
            "     24        \u001b[36m0.6655\u001b[0m  0.0307\n",
            "     25        \u001b[36m0.6654\u001b[0m  0.0335\n",
            "     26        \u001b[36m0.6654\u001b[0m  0.0321\n",
            "     27        \u001b[36m0.6653\u001b[0m  0.0311\n",
            "     28        \u001b[36m0.6653\u001b[0m  0.0326\n",
            "     29        \u001b[36m0.6653\u001b[0m  0.0316\n",
            "     30        \u001b[36m0.6652\u001b[0m  0.0327\n",
            "     31        \u001b[36m0.6652\u001b[0m  0.0317\n",
            "     32        \u001b[36m0.6652\u001b[0m  0.0322\n",
            "     33        \u001b[36m0.6651\u001b[0m  0.0299\n",
            "     34        \u001b[36m0.6651\u001b[0m  0.0316\n",
            "     35        \u001b[36m0.6651\u001b[0m  0.0316\n",
            "     36        \u001b[36m0.6651\u001b[0m  0.0322\n",
            "     37        \u001b[36m0.6650\u001b[0m  0.0312\n",
            "     38        0.6679  0.0317\n",
            "     39        0.6678  0.0327\n",
            "     40        \u001b[36m0.6648\u001b[0m  0.0341\n",
            "     41        0.6684  0.0296\n",
            "     42        0.6674  0.0335\n",
            "     43        \u001b[36m0.6640\u001b[0m  0.0336\n",
            "     44        0.6663  0.0327\n",
            "     45        0.6641  0.0306\n",
            "     46        \u001b[36m0.6634\u001b[0m  0.0331\n",
            "     47        \u001b[36m0.6629\u001b[0m  0.0290\n",
            "     48        \u001b[36m0.6623\u001b[0m  0.0322\n",
            "     49        \u001b[36m0.6607\u001b[0m  0.0327\n",
            "     50        \u001b[36m0.6524\u001b[0m  0.0312\n",
            "     51        \u001b[36m0.6468\u001b[0m  0.0331\n",
            "     52        \u001b[36m0.6425\u001b[0m  0.0312\n",
            "     53        \u001b[36m0.6411\u001b[0m  0.0328\n",
            "     54        \u001b[36m0.6390\u001b[0m  0.0310\n",
            "     55        \u001b[36m0.6372\u001b[0m  0.0326\n",
            "     56        \u001b[36m0.6356\u001b[0m  0.0341\n",
            "     57        \u001b[36m0.6341\u001b[0m  0.0306\n",
            "     58        \u001b[36m0.6328\u001b[0m  0.0336\n",
            "     59        \u001b[36m0.6316\u001b[0m  0.0297\n",
            "     60        \u001b[36m0.6305\u001b[0m  0.0326\n",
            "     61        \u001b[36m0.6295\u001b[0m  0.0354\n",
            "     62        \u001b[36m0.6285\u001b[0m  0.0351\n",
            "     63        \u001b[36m0.6277\u001b[0m  0.0328\n",
            "     64        \u001b[36m0.6269\u001b[0m  0.0312\n",
            "     65        0.6508  0.0330\n",
            "     66        0.6312  0.0316\n",
            "     67        0.6314  0.0321\n",
            "     68        \u001b[36m0.6228\u001b[0m  0.0320\n",
            "     69        \u001b[36m0.6116\u001b[0m  0.0312\n",
            "     70        \u001b[36m0.6092\u001b[0m  0.0336\n",
            "     71        0.6174  0.0333\n",
            "     72        \u001b[36m0.6045\u001b[0m  0.0331\n",
            "     73        \u001b[36m0.6045\u001b[0m  0.0311\n",
            "     74        0.6117  0.0291\n",
            "     75        0.6099  0.0323\n",
            "     76        \u001b[36m0.6044\u001b[0m  0.0307\n",
            "     77        \u001b[36m0.5971\u001b[0m  0.0311\n",
            "     78        0.6137  0.0313\n",
            "     79        0.6016  0.0339\n",
            "     80        0.5997  0.0341\n",
            "     81        0.5991  0.0318\n",
            "     82        0.5985  0.0310\n",
            "     83        0.5980  0.0386\n",
            "     84        0.5975  0.0427\n",
            "     85        \u001b[36m0.5970\u001b[0m  0.0337\n",
            "     86        \u001b[36m0.5964\u001b[0m  0.0311\n",
            "     87        0.7078  0.0317\n",
            "     88        0.6660  0.0341\n",
            "     89        0.6109  0.0331\n",
            "     90        0.6414  0.0308\n",
            "     91        0.6449  0.0331\n",
            "     92        0.6324  0.0311\n",
            "     93        0.6300  0.0332\n",
            "     94        0.6298  0.0316\n",
            "     95        0.5974  0.0322\n",
            "     96        0.6201  0.0298\n",
            "     97        0.6242  0.0311\n",
            "     98        0.6092  0.0326\n",
            "     99        0.6062  0.0330\n",
            "    100        0.6042  0.0333\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.5762\u001b[0m  0.0200\n",
            "      2        \u001b[36m1.5422\u001b[0m  0.0211\n",
            "      3        \u001b[36m1.5085\u001b[0m  0.0223\n",
            "      4        \u001b[36m1.4751\u001b[0m  0.0212\n",
            "      5        \u001b[36m1.4420\u001b[0m  0.0212\n",
            "      6        \u001b[36m1.4093\u001b[0m  0.0220\n",
            "      7        \u001b[36m1.3770\u001b[0m  0.0227\n",
            "      8        \u001b[36m1.3452\u001b[0m  0.0220\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      9        \u001b[36m1.3138\u001b[0m  0.0226\n",
            "     10        \u001b[36m1.2829\u001b[0m  0.0241\n",
            "     11        \u001b[36m1.2525\u001b[0m  0.0233\n",
            "     12        \u001b[36m1.2227\u001b[0m  0.0215\n",
            "     13        \u001b[36m1.1935\u001b[0m  0.0232\n",
            "     14        \u001b[36m1.1650\u001b[0m  0.0211\n",
            "     15        \u001b[36m1.1372\u001b[0m  0.0193\n",
            "     16        \u001b[36m1.1100\u001b[0m  0.0236\n",
            "     17        \u001b[36m1.0837\u001b[0m  0.0227\n",
            "     18        \u001b[36m1.0581\u001b[0m  0.0225\n",
            "     19        \u001b[36m1.0333\u001b[0m  0.0201\n",
            "     20        \u001b[36m1.0094\u001b[0m  0.0211\n",
            "     21        \u001b[36m0.9864\u001b[0m  0.0211\n",
            "     22        \u001b[36m0.9642\u001b[0m  0.0215\n",
            "     23        \u001b[36m0.9430\u001b[0m  0.0201\n",
            "     24        \u001b[36m0.9228\u001b[0m  0.0201\n",
            "     25        \u001b[36m0.9035\u001b[0m  0.0251\n",
            "     26        \u001b[36m0.8851\u001b[0m  0.0236\n",
            "     27        \u001b[36m0.8677\u001b[0m  0.0231\n",
            "     28        \u001b[36m0.8513\u001b[0m  0.0211\n",
            "     29        \u001b[36m0.8358\u001b[0m  0.0222\n",
            "     30        \u001b[36m0.8213\u001b[0m  0.0225\n",
            "     31        \u001b[36m0.8077\u001b[0m  0.0226\n",
            "     32        \u001b[36m0.7949\u001b[0m  0.0206\n",
            "     33        \u001b[36m0.7831\u001b[0m  0.0226\n",
            "     34        \u001b[36m0.7721\u001b[0m  0.0222\n",
            "     35        \u001b[36m0.7619\u001b[0m  0.0235\n",
            "     36        \u001b[36m0.7525\u001b[0m  0.0229\n",
            "     37        \u001b[36m0.7438\u001b[0m  0.0206\n",
            "     38        \u001b[36m0.7358\u001b[0m  0.0206\n",
            "     39        \u001b[36m0.7285\u001b[0m  0.0218\n",
            "     40        \u001b[36m0.7218\u001b[0m  0.0206\n",
            "     41        \u001b[36m0.7157\u001b[0m  0.0227\n",
            "     42        \u001b[36m0.7101\u001b[0m  0.0230\n",
            "     43        \u001b[36m0.7051\u001b[0m  0.0216\n",
            "     44        \u001b[36m0.7005\u001b[0m  0.0201\n",
            "     45        \u001b[36m0.6963\u001b[0m  0.0231\n",
            "     46        \u001b[36m0.6926\u001b[0m  0.0206\n",
            "     47        \u001b[36m0.6892\u001b[0m  0.0216\n",
            "     48        \u001b[36m0.6861\u001b[0m  0.0217\n",
            "     49        \u001b[36m0.6834\u001b[0m  0.0221\n",
            "     50        \u001b[36m0.6809\u001b[0m  0.0221\n",
            "     51        \u001b[36m0.6787\u001b[0m  0.0206\n",
            "     52        \u001b[36m0.6767\u001b[0m  0.0209\n",
            "     53        \u001b[36m0.6750\u001b[0m  0.0223\n",
            "     54        \u001b[36m0.6734\u001b[0m  0.0235\n",
            "     55        \u001b[36m0.6720\u001b[0m  0.0222\n",
            "     56        \u001b[36m0.6707\u001b[0m  0.0220\n",
            "     57        \u001b[36m0.6696\u001b[0m  0.0211\n",
            "     58        \u001b[36m0.6686\u001b[0m  0.0203\n",
            "     59        \u001b[36m0.6677\u001b[0m  0.0217\n",
            "     60        \u001b[36m0.6669\u001b[0m  0.0231\n",
            "     61        \u001b[36m0.6662\u001b[0m  0.0217\n",
            "     62        \u001b[36m0.6656\u001b[0m  0.0229\n",
            "     63        \u001b[36m0.6650\u001b[0m  0.0221\n",
            "     64        \u001b[36m0.6645\u001b[0m  0.0220\n",
            "     65        \u001b[36m0.6641\u001b[0m  0.0210\n",
            "     66        \u001b[36m0.6637\u001b[0m  0.0211\n",
            "     67        \u001b[36m0.6634\u001b[0m  0.0241\n",
            "     68        \u001b[36m0.6631\u001b[0m  0.0212\n",
            "     69        \u001b[36m0.6628\u001b[0m  0.0201\n",
            "     70        \u001b[36m0.6626\u001b[0m  0.0223\n",
            "     71        \u001b[36m0.6624\u001b[0m  0.0213\n",
            "     72        \u001b[36m0.6622\u001b[0m  0.0227\n",
            "     73        \u001b[36m0.6621\u001b[0m  0.0230\n",
            "     74        \u001b[36m0.6619\u001b[0m  0.0239\n",
            "     75        \u001b[36m0.6618\u001b[0m  0.0230\n",
            "     76        \u001b[36m0.6617\u001b[0m  0.0201\n",
            "     77        \u001b[36m0.6616\u001b[0m  0.0221\n",
            "     78        \u001b[36m0.6615\u001b[0m  0.0217\n",
            "     79        \u001b[36m0.6615\u001b[0m  0.0226\n",
            "     80        \u001b[36m0.6614\u001b[0m  0.0231\n",
            "     81        \u001b[36m0.6613\u001b[0m  0.0221\n",
            "     82        \u001b[36m0.6613\u001b[0m  0.0216\n",
            "     83        \u001b[36m0.6613\u001b[0m  0.0243\n",
            "     84        \u001b[36m0.6612\u001b[0m  0.0206\n",
            "     85        \u001b[36m0.6612\u001b[0m  0.0231\n",
            "     86        \u001b[36m0.6612\u001b[0m  0.0202\n",
            "     87        \u001b[36m0.6612\u001b[0m  0.0216\n",
            "     88        \u001b[36m0.6611\u001b[0m  0.0246\n",
            "     89        \u001b[36m0.6611\u001b[0m  0.0221\n",
            "     90        \u001b[36m0.6611\u001b[0m  0.0226\n",
            "     91        \u001b[36m0.6611\u001b[0m  0.0222\n",
            "     92        \u001b[36m0.6611\u001b[0m  0.0216\n",
            "     93        \u001b[36m0.6611\u001b[0m  0.0238\n",
            "     94        \u001b[36m0.6611\u001b[0m  0.0216\n",
            "     95        \u001b[36m0.6611\u001b[0m  0.0221\n",
            "     96        \u001b[36m0.6611\u001b[0m  0.0233\n",
            "     97        \u001b[36m0.6611\u001b[0m  0.0211\n",
            "     98        \u001b[36m0.6611\u001b[0m  0.0231\n",
            "     99        \u001b[36m0.6611\u001b[0m  0.0221\n",
            "    100        \u001b[36m0.6611\u001b[0m  0.0220\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.5111\u001b[0m  0.0219\n",
            "      2        \u001b[36m1.4793\u001b[0m  0.0222\n",
            "      3        \u001b[36m1.4478\u001b[0m  0.0210\n",
            "      4        \u001b[36m1.4167\u001b[0m  0.0230\n",
            "      5        \u001b[36m1.3860\u001b[0m  0.0216\n",
            "      6        \u001b[36m1.3556\u001b[0m  0.0221\n",
            "      7        \u001b[36m1.3257\u001b[0m  0.0190\n",
            "      8        \u001b[36m1.2962\u001b[0m  0.0233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      9        \u001b[36m1.2672\u001b[0m  0.0236\n",
            "     10        \u001b[36m1.2387\u001b[0m  0.0211\n",
            "     11        \u001b[36m1.2107\u001b[0m  0.0221\n",
            "     12        \u001b[36m1.1833\u001b[0m  0.0206\n",
            "     13        \u001b[36m1.1565\u001b[0m  0.0219\n",
            "     14        \u001b[36m1.1303\u001b[0m  0.0226\n",
            "     15        \u001b[36m1.1048\u001b[0m  0.0209\n",
            "     16        \u001b[36m1.0800\u001b[0m  0.0238\n",
            "     17        \u001b[36m1.0559\u001b[0m  0.0215\n",
            "     18        \u001b[36m1.0326\u001b[0m  0.0217\n",
            "     19        \u001b[36m1.0100\u001b[0m  0.0236\n",
            "     20        \u001b[36m0.9883\u001b[0m  0.0216\n",
            "     21        \u001b[36m0.9673\u001b[0m  0.0231\n",
            "     22        \u001b[36m0.9472\u001b[0m  0.0209\n",
            "     23        \u001b[36m0.9280\u001b[0m  0.0221\n",
            "     24        \u001b[36m0.9096\u001b[0m  0.0216\n",
            "     25        \u001b[36m0.8920\u001b[0m  0.0216\n",
            "     26        \u001b[36m0.8754\u001b[0m  0.0239\n",
            "     27        \u001b[36m0.8596\u001b[0m  0.0220\n",
            "     28        \u001b[36m0.8446\u001b[0m  0.0241\n",
            "     29        \u001b[36m0.8305\u001b[0m  0.0196\n",
            "     30        \u001b[36m0.8173\u001b[0m  0.0206\n",
            "     31        \u001b[36m0.8048\u001b[0m  0.0216\n",
            "     32        \u001b[36m0.7932\u001b[0m  0.0210\n",
            "     33        \u001b[36m0.7823\u001b[0m  0.0219\n",
            "     34        \u001b[36m0.7721\u001b[0m  0.0222\n",
            "     35        \u001b[36m0.7627\u001b[0m  0.0231\n",
            "     36        \u001b[36m0.7539\u001b[0m  0.0213\n",
            "     37        \u001b[36m0.7458\u001b[0m  0.0226\n",
            "     38        \u001b[36m0.7384\u001b[0m  0.0211\n",
            "     39        \u001b[36m0.7315\u001b[0m  0.0216\n",
            "     40        \u001b[36m0.7251\u001b[0m  0.0221\n",
            "     41        \u001b[36m0.7193\u001b[0m  0.0206\n",
            "     42        \u001b[36m0.7139\u001b[0m  0.0221\n",
            "     43        \u001b[36m0.7090\u001b[0m  0.0221\n",
            "     44        \u001b[36m0.7046\u001b[0m  0.0217\n",
            "     45        \u001b[36m0.7005\u001b[0m  0.0241\n",
            "     46        \u001b[36m0.6968\u001b[0m  0.0206\n",
            "     47        \u001b[36m0.6934\u001b[0m  0.0231\n",
            "     48        \u001b[36m0.6903\u001b[0m  0.0237\n",
            "     49        \u001b[36m0.6875\u001b[0m  0.0236\n",
            "     50        \u001b[36m0.6849\u001b[0m  0.0227\n",
            "     51        \u001b[36m0.6826\u001b[0m  0.0200\n",
            "     52        \u001b[36m0.6805\u001b[0m  0.0232\n",
            "     53        \u001b[36m0.6787\u001b[0m  0.0291\n",
            "     54        \u001b[36m0.6769\u001b[0m  0.0297\n",
            "     55        \u001b[36m0.6754\u001b[0m  0.0211\n",
            "     56        \u001b[36m0.6740\u001b[0m  0.0240\n",
            "     57        \u001b[36m0.6727\u001b[0m  0.0221\n",
            "     58        \u001b[36m0.6716\u001b[0m  0.0224\n",
            "     59        \u001b[36m0.6705\u001b[0m  0.0220\n",
            "     60        \u001b[36m0.6696\u001b[0m  0.0216\n",
            "     61        \u001b[36m0.6688\u001b[0m  0.0221\n",
            "     62        \u001b[36m0.6680\u001b[0m  0.0214\n",
            "     63        \u001b[36m0.6673\u001b[0m  0.0231\n",
            "     64        \u001b[36m0.6667\u001b[0m  0.0219\n",
            "     65        \u001b[36m0.6661\u001b[0m  0.0231\n",
            "     66        \u001b[36m0.6656\u001b[0m  0.0210\n",
            "     67        \u001b[36m0.6652\u001b[0m  0.0221\n",
            "     68        \u001b[36m0.6648\u001b[0m  0.0236\n",
            "     69        \u001b[36m0.6644\u001b[0m  0.0226\n",
            "     70        \u001b[36m0.6640\u001b[0m  0.0231\n",
            "     71        \u001b[36m0.6637\u001b[0m  0.0206\n",
            "     72        \u001b[36m0.6635\u001b[0m  0.0231\n",
            "     73        \u001b[36m0.6632\u001b[0m  0.0210\n",
            "     74        \u001b[36m0.6630\u001b[0m  0.0221\n",
            "     75        \u001b[36m0.6628\u001b[0m  0.0227\n",
            "     76        \u001b[36m0.6626\u001b[0m  0.0221\n",
            "     77        \u001b[36m0.6624\u001b[0m  0.0205\n",
            "     78        \u001b[36m0.6623\u001b[0m  0.0206\n",
            "     79        \u001b[36m0.6621\u001b[0m  0.0196\n",
            "     80        \u001b[36m0.6620\u001b[0m  0.0211\n",
            "     81        \u001b[36m0.6619\u001b[0m  0.0221\n",
            "     82        \u001b[36m0.6618\u001b[0m  0.0246\n",
            "     83        \u001b[36m0.6617\u001b[0m  0.0241\n",
            "     84        \u001b[36m0.6616\u001b[0m  0.0230\n",
            "     85        \u001b[36m0.6615\u001b[0m  0.0210\n",
            "     86        \u001b[36m0.6614\u001b[0m  0.0218\n",
            "     87        \u001b[36m0.6614\u001b[0m  0.0222\n",
            "     88        \u001b[36m0.6613\u001b[0m  0.0230\n",
            "     89        \u001b[36m0.6613\u001b[0m  0.0221\n",
            "     90        \u001b[36m0.6612\u001b[0m  0.0212\n",
            "     91        \u001b[36m0.6612\u001b[0m  0.0226\n",
            "     92        \u001b[36m0.6611\u001b[0m  0.0210\n",
            "     93        \u001b[36m0.6611\u001b[0m  0.0231\n",
            "     94        \u001b[36m0.6610\u001b[0m  0.0221\n",
            "     95        \u001b[36m0.6610\u001b[0m  0.0223\n",
            "     96        \u001b[36m0.6610\u001b[0m  0.0196\n",
            "     97        \u001b[36m0.6610\u001b[0m  0.0212\n",
            "     98        \u001b[36m0.6609\u001b[0m  0.0196\n",
            "     99        \u001b[36m0.6609\u001b[0m  0.0232\n",
            "    100        \u001b[36m0.6609\u001b[0m  0.0230\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.6974\u001b[0m  0.0316\n",
            "      2        \u001b[36m2.5707\u001b[0m  0.0326\n",
            "      3        \u001b[36m2.4390\u001b[0m  0.0301\n",
            "      4        \u001b[36m2.3043\u001b[0m  0.0299\n",
            "      5        \u001b[36m2.1681\u001b[0m  0.0308\n",
            "      6        \u001b[36m2.0287\u001b[0m  0.0341"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      7        \u001b[36m1.8666\u001b[0m  0.0323\n",
            "      8        \u001b[36m1.5984\u001b[0m  0.0326\n",
            "      9        \u001b[36m1.1698\u001b[0m  0.0331\n",
            "     10        \u001b[36m0.8075\u001b[0m  0.0326\n",
            "     11        \u001b[36m0.6951\u001b[0m  0.0331\n",
            "     12        \u001b[36m0.6748\u001b[0m  0.0326\n",
            "     13        \u001b[36m0.6708\u001b[0m  0.0337\n",
            "     14        \u001b[36m0.6696\u001b[0m  0.0332\n",
            "     15        \u001b[36m0.6690\u001b[0m  0.0332\n",
            "     16        \u001b[36m0.6688\u001b[0m  0.0316\n",
            "     17        \u001b[36m0.6686\u001b[0m  0.0343\n",
            "     18        \u001b[36m0.6684\u001b[0m  0.0316\n",
            "     19        \u001b[36m0.6684\u001b[0m  0.0341\n",
            "     20        \u001b[36m0.6683\u001b[0m  0.0301\n",
            "     21        \u001b[36m0.6682\u001b[0m  0.0311\n",
            "     22        \u001b[36m0.6682\u001b[0m  0.0309\n",
            "     23        \u001b[36m0.6682\u001b[0m  0.0328\n",
            "     24        \u001b[36m0.6681\u001b[0m  0.0301\n",
            "     25        \u001b[36m0.6681\u001b[0m  0.0326\n",
            "     26        \u001b[36m0.6680\u001b[0m  0.0318\n",
            "     27        \u001b[36m0.6680\u001b[0m  0.0321\n",
            "     28        \u001b[36m0.6680\u001b[0m  0.0321\n",
            "     29        \u001b[36m0.6679\u001b[0m  0.0344\n",
            "     30        \u001b[36m0.6679\u001b[0m  0.0326\n",
            "     31        \u001b[36m0.6678\u001b[0m  0.0342\n",
            "     32        \u001b[36m0.6678\u001b[0m  0.0327\n",
            "     33        \u001b[36m0.6677\u001b[0m  0.0301\n",
            "     34        \u001b[36m0.6677\u001b[0m  0.0326\n",
            "     35        \u001b[36m0.6676\u001b[0m  0.0331\n",
            "     36        \u001b[36m0.6676\u001b[0m  0.0317\n",
            "     37        \u001b[36m0.6676\u001b[0m  0.0310\n",
            "     38        \u001b[36m0.6676\u001b[0m  0.0302\n",
            "     39        \u001b[36m0.6675\u001b[0m  0.0331\n",
            "     40        \u001b[36m0.6675\u001b[0m  0.0336\n",
            "     41        \u001b[36m0.6675\u001b[0m  0.0317\n",
            "     42        \u001b[36m0.6675\u001b[0m  0.0327\n",
            "     43        0.6675  0.0326\n",
            "     44        \u001b[36m0.6674\u001b[0m  0.0332\n",
            "     45        0.6716  0.0321\n",
            "     46        0.7117  0.0316\n",
            "     47        0.6874  0.0332\n",
            "     48        0.6781  0.0326\n",
            "     49        0.6753  0.0297\n",
            "     50        0.6685  0.0296\n",
            "     51        0.7260  0.0321\n",
            "     52        0.6960  0.0338\n",
            "     53        0.6858  0.0310\n",
            "     54        0.6830  0.0326\n",
            "     55        0.6679  0.0301\n",
            "     56        0.7388  0.0312\n",
            "     57        0.7001  0.0341\n",
            "     58        0.6938  0.0331\n",
            "     59        0.6954  0.0316\n",
            "     60        0.6858  0.0347\n",
            "     61        0.7003  0.0321\n",
            "     62        0.6884  0.0332\n",
            "     63        0.6832  0.0341\n",
            "     64        0.6822  0.0327\n",
            "     65        0.6761  0.0341\n",
            "     66        0.6707  0.0491\n",
            "     67        \u001b[36m0.6661\u001b[0m  0.0346\n",
            "     68        \u001b[36m0.6628\u001b[0m  0.0341\n",
            "     69        \u001b[36m0.6601\u001b[0m  0.0342\n",
            "     70        \u001b[36m0.6580\u001b[0m  0.0322\n",
            "     71        \u001b[36m0.6562\u001b[0m  0.0335\n",
            "     72        \u001b[36m0.6547\u001b[0m  0.0330\n",
            "     73        \u001b[36m0.6533\u001b[0m  0.0329\n",
            "     74        \u001b[36m0.6521\u001b[0m  0.0336\n",
            "     75        \u001b[36m0.6510\u001b[0m  0.0317\n",
            "     76        \u001b[36m0.6500\u001b[0m  0.0330\n",
            "     77        \u001b[36m0.6491\u001b[0m  0.0297\n",
            "     78        \u001b[36m0.6483\u001b[0m  0.0321\n",
            "     79        \u001b[36m0.6469\u001b[0m  0.0311\n",
            "     80        \u001b[36m0.6452\u001b[0m  0.0337\n",
            "     81        \u001b[36m0.6210\u001b[0m  0.0326\n",
            "     82        0.6709  0.0326\n",
            "     83        0.6304  0.0331\n",
            "     84        0.6266  0.0298\n",
            "     85        \u001b[36m0.6111\u001b[0m  0.0312\n",
            "     86        0.6118  0.0313\n",
            "     87        0.6294  0.0297\n",
            "     88        0.6231  0.0328\n",
            "     89        \u001b[36m0.6097\u001b[0m  0.0326\n",
            "     90        \u001b[36m0.6015\u001b[0m  0.0320\n",
            "     91        \u001b[36m0.5936\u001b[0m  0.0331\n",
            "     92        0.5943  0.0344\n",
            "     93        0.6198  0.0336\n",
            "     94        \u001b[36m0.5827\u001b[0m  0.0306\n",
            "     95        0.6017  0.0317\n",
            "     96        0.5975  0.0321\n",
            "     97        0.5910  0.0327\n",
            "     98        0.6239  0.0311\n",
            "     99        0.6166  0.0311\n",
            "    100        0.5914  0.0327\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2612\u001b[0m  0.0321\n",
            "      2        \u001b[36m2.1311\u001b[0m  0.0322\n",
            "      3        \u001b[36m2.0027\u001b[0m  0.0331\n",
            "      4        \u001b[36m1.8723\u001b[0m  0.0341\n",
            "      5        \u001b[36m1.7417\u001b[0m  0.0326\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      6        \u001b[36m1.6123\u001b[0m  0.0331\n",
            "      7        \u001b[36m1.4851\u001b[0m  0.0320\n",
            "      8        \u001b[36m1.3601\u001b[0m  0.0322\n",
            "      9        \u001b[36m1.2281\u001b[0m  0.0325\n",
            "     10        \u001b[36m1.0634\u001b[0m  0.0331\n",
            "     11        \u001b[36m0.8767\u001b[0m  0.0334\n",
            "     12        \u001b[36m0.7321\u001b[0m  0.0321\n",
            "     13        \u001b[36m0.6801\u001b[0m  0.0332\n",
            "     14        \u001b[36m0.6709\u001b[0m  0.0314\n",
            "     15        \u001b[36m0.6692\u001b[0m  0.0326\n",
            "     16        \u001b[36m0.6686\u001b[0m  0.0557\n",
            "     17        \u001b[36m0.6683\u001b[0m  0.0337\n",
            "     18        \u001b[36m0.6680\u001b[0m  0.0317\n",
            "     19        \u001b[36m0.6678\u001b[0m  0.0321\n",
            "     20        \u001b[36m0.6677\u001b[0m  0.0334\n",
            "     21        \u001b[36m0.6676\u001b[0m  0.0331\n",
            "     22        \u001b[36m0.6672\u001b[0m  0.0316\n",
            "     23        \u001b[36m0.6499\u001b[0m  0.0321\n",
            "     24        0.6893  0.0310\n",
            "     25        0.6823  0.0327\n",
            "     26        0.6777  0.0328\n",
            "     27        0.6753  0.0336\n",
            "     28        0.6739  0.0312\n",
            "     29        0.6729  0.0316\n",
            "     30        0.6721  0.0331\n",
            "     31        0.6714  0.0331\n",
            "     32        0.6707  0.0341\n",
            "     33        0.6700  0.0301\n",
            "     34        0.6694  0.0351\n",
            "     35        0.6687  0.0322\n",
            "     36        0.6681  0.0316\n",
            "     37        0.6674  0.0343\n",
            "     38        0.6667  0.0381\n",
            "     39        0.6661  0.0347\n",
            "     40        0.6654  0.0341\n",
            "     41        0.6647  0.0341\n",
            "     42        0.6638  0.0316\n",
            "     43        0.6629  0.0326\n",
            "     44        0.6615  0.0320\n",
            "     45        \u001b[36m0.6453\u001b[0m  0.0336\n",
            "     46        0.6760  0.0297\n",
            "     47        0.6606  0.0327\n",
            "     48        0.6525  0.0321\n",
            "     49        0.6497  0.0341\n",
            "     50        0.6461  0.0290\n",
            "     51        \u001b[36m0.6411\u001b[0m  0.0331\n",
            "     52        \u001b[36m0.6335\u001b[0m  0.0341\n",
            "     53        0.6461  0.0337\n",
            "     54        0.6385  0.0329\n",
            "     55        0.6403  0.0300\n",
            "     56        0.6408  0.0316\n",
            "     57        0.6416  0.0341\n",
            "     58        0.6397  0.0330\n",
            "     59        0.6348  0.0324\n",
            "     60        0.6361  0.0316\n",
            "     61        \u001b[36m0.6147\u001b[0m  0.0326\n",
            "     62        0.6445  0.0309\n",
            "     63        0.6280  0.0326\n",
            "     64        0.6264  0.0329\n",
            "     65        \u001b[36m0.6143\u001b[0m  0.0326\n",
            "     66        0.6194  0.0316\n",
            "     67        \u001b[36m0.6052\u001b[0m  0.0302\n",
            "     68        \u001b[36m0.5893\u001b[0m  0.0321\n",
            "     69        0.6013  0.0330\n",
            "     70        \u001b[36m0.5646\u001b[0m  0.0346\n",
            "     71        0.6084  0.0335\n",
            "     72        0.5804  0.0336\n",
            "     73        0.5816  0.0322\n",
            "     74        0.5730  0.0313\n",
            "     75        0.5799  0.0327\n",
            "     76        0.5769  0.0311\n",
            "     77        0.5687  0.0337\n",
            "     78        0.5733  0.0317\n",
            "     79        0.6287  0.0351\n",
            "     80        0.6219  0.0361\n",
            "     81        \u001b[36m0.5500\u001b[0m  0.0361\n",
            "     82        0.5648  0.0321\n",
            "     83        0.5804  0.0316\n",
            "     84        0.5753  0.0331\n",
            "     85        0.5829  0.0317\n",
            "     86        0.5695  0.0347\n",
            "     87        0.5679  0.0316\n",
            "     88        0.5689  0.0311\n",
            "     89        0.5688  0.0340\n",
            "     90        0.5684  0.0312\n",
            "     91        0.5681  0.0326\n",
            "     92        0.5678  0.0315\n",
            "     93        0.5676  0.0355\n",
            "     94        0.5674  0.0342\n",
            "     95        0.5671  0.0351\n",
            "     96        0.5669  0.0341\n",
            "     97        0.5667  0.0391\n",
            "     98        0.5666  0.0382\n",
            "     99        0.5664  0.0362\n",
            "    100        0.5662  0.0366\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.0678\u001b[0m  0.0230\n",
            "      2        \u001b[36m2.9978\u001b[0m  0.0251\n",
            "      3        \u001b[36m2.9278\u001b[0m  0.0231\n",
            "      4        \u001b[36m2.8579\u001b[0m  0.0216\n",
            "      5        \u001b[36m2.7880\u001b[0m  0.0218\n",
            "      6        \u001b[36m2.7181\u001b[0m  0.0262\n",
            "      7        \u001b[36m2.6482\u001b[0m  0.0230\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      8        \u001b[36m2.5785\u001b[0m  0.0200\n",
            "      9        \u001b[36m2.5088\u001b[0m  0.0286\n",
            "     10        \u001b[36m2.4391\u001b[0m  0.0265\n",
            "     11        \u001b[36m2.3696\u001b[0m  0.0211\n",
            "     12        \u001b[36m2.3002\u001b[0m  0.0221\n",
            "     13        \u001b[36m2.2310\u001b[0m  0.0231\n",
            "     14        \u001b[36m2.1619\u001b[0m  0.0220\n",
            "     15        \u001b[36m2.0931\u001b[0m  0.0220\n",
            "     16        \u001b[36m2.0245\u001b[0m  0.0246\n",
            "     17        \u001b[36m1.9562\u001b[0m  0.0230\n",
            "     18        \u001b[36m1.8883\u001b[0m  0.0236\n",
            "     19        \u001b[36m1.8208\u001b[0m  0.0232\n",
            "     20        \u001b[36m1.7538\u001b[0m  0.0226\n",
            "     21        \u001b[36m1.6875\u001b[0m  0.0230\n",
            "     22        \u001b[36m1.6219\u001b[0m  0.0222\n",
            "     23        \u001b[36m1.5571\u001b[0m  0.0214\n",
            "     24        \u001b[36m1.4934\u001b[0m  0.0227\n",
            "     25        \u001b[36m1.4308\u001b[0m  0.0230\n",
            "     26        \u001b[36m1.3697\u001b[0m  0.0264\n",
            "     27        \u001b[36m1.3101\u001b[0m  0.0237\n",
            "     28        \u001b[36m1.2523\u001b[0m  0.0231\n",
            "     29        \u001b[36m1.1966\u001b[0m  0.0427\n",
            "     30        \u001b[36m1.1432\u001b[0m  0.0291\n",
            "     31        \u001b[36m1.0923\u001b[0m  0.0236\n",
            "     32        \u001b[36m1.0442\u001b[0m  0.0221\n",
            "     33        \u001b[36m0.9992\u001b[0m  0.0248\n",
            "     34        \u001b[36m0.9573\u001b[0m  0.0273\n",
            "     35        \u001b[36m0.9187\u001b[0m  0.0251\n",
            "     36        \u001b[36m0.8836\u001b[0m  0.0236\n",
            "     37        \u001b[36m0.8518\u001b[0m  0.0242\n",
            "     38        \u001b[36m0.8235\u001b[0m  0.0210\n",
            "     39        \u001b[36m0.7984\u001b[0m  0.0231\n",
            "     40        \u001b[36m0.7765\u001b[0m  0.0220\n",
            "     41        \u001b[36m0.7574\u001b[0m  0.0222\n",
            "     42        \u001b[36m0.7411\u001b[0m  0.0226\n",
            "     43        \u001b[36m0.7272\u001b[0m  0.0221\n",
            "     44        \u001b[36m0.7154\u001b[0m  0.0220\n",
            "     45        \u001b[36m0.7056\u001b[0m  0.0221\n",
            "     46        \u001b[36m0.6974\u001b[0m  0.0226\n",
            "     47        \u001b[36m0.6906\u001b[0m  0.0231\n",
            "     48        \u001b[36m0.6850\u001b[0m  0.0237\n",
            "     49        \u001b[36m0.6804\u001b[0m  0.0226\n",
            "     50        \u001b[36m0.6766\u001b[0m  0.0226\n",
            "     51        \u001b[36m0.6736\u001b[0m  0.0235\n",
            "     52        \u001b[36m0.6712\u001b[0m  0.0231\n",
            "     53        \u001b[36m0.6692\u001b[0m  0.0260\n",
            "     54        \u001b[36m0.6676\u001b[0m  0.0271\n",
            "     55        \u001b[36m0.6663\u001b[0m  0.0241\n",
            "     56        \u001b[36m0.6653\u001b[0m  0.0231\n",
            "     57        \u001b[36m0.6645\u001b[0m  0.0265\n",
            "     58        \u001b[36m0.6638\u001b[0m  0.0256\n",
            "     59        \u001b[36m0.6633\u001b[0m  0.0251\n",
            "     60        \u001b[36m0.6629\u001b[0m  0.0216\n",
            "     61        \u001b[36m0.6626\u001b[0m  0.0216\n",
            "     62        \u001b[36m0.6623\u001b[0m  0.0231\n",
            "     63        \u001b[36m0.6621\u001b[0m  0.0241\n",
            "     64        \u001b[36m0.6619\u001b[0m  0.0225\n",
            "     65        \u001b[36m0.6618\u001b[0m  0.0221\n",
            "     66        \u001b[36m0.6617\u001b[0m  0.0230\n",
            "     67        \u001b[36m0.6616\u001b[0m  0.0240\n",
            "     68        \u001b[36m0.6616\u001b[0m  0.0258\n",
            "     69        \u001b[36m0.6615\u001b[0m  0.0271\n",
            "     70        \u001b[36m0.6615\u001b[0m  0.0241\n",
            "     71        \u001b[36m0.6615\u001b[0m  0.0236\n",
            "     72        \u001b[36m0.6614\u001b[0m  0.0223\n",
            "     73        \u001b[36m0.6614\u001b[0m  0.0231\n",
            "     74        \u001b[36m0.6614\u001b[0m  0.0231\n",
            "     75        \u001b[36m0.6614\u001b[0m  0.0241\n",
            "     76        \u001b[36m0.6614\u001b[0m  0.0210\n",
            "     77        \u001b[36m0.6614\u001b[0m  0.0203\n",
            "     78        \u001b[36m0.6614\u001b[0m  0.0226\n",
            "     79        \u001b[36m0.6614\u001b[0m  0.0218\n",
            "     80        \u001b[36m0.6614\u001b[0m  0.0231\n",
            "     81        \u001b[36m0.6614\u001b[0m  0.0211\n",
            "     82        \u001b[36m0.6614\u001b[0m  0.0212\n",
            "     83        \u001b[36m0.6614\u001b[0m  0.0236\n",
            "     84        \u001b[36m0.6614\u001b[0m  0.0241\n",
            "     85        \u001b[36m0.6614\u001b[0m  0.0220\n",
            "     86        0.6614  0.0210\n",
            "     87        0.6614  0.0233\n",
            "     88        0.6614  0.0242\n",
            "     89        0.6614  0.0222\n",
            "     90        0.6614  0.0251\n",
            "     91        0.6614  0.0251\n",
            "     92        0.6614  0.0282\n",
            "     93        0.6614  0.0269\n",
            "     94        0.6614  0.0291\n",
            "     95        0.6614  0.0271\n",
            "     96        0.6614  0.0319\n",
            "     97        0.6614  0.0372\n",
            "     98        0.6614  0.0230\n",
            "     99        0.6614  0.0234\n",
            "    100        0.6614  0.0223\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.1552\u001b[0m  0.0225\n",
            "      2        \u001b[36m4.0882\u001b[0m  0.0227\n",
            "      3        \u001b[36m4.0212\u001b[0m  0.0207\n",
            "      4        \u001b[36m3.9541\u001b[0m  0.0233\n",
            "      5        \u001b[36m3.8871\u001b[0m  0.0221\n",
            "      6        \u001b[36m3.8201\u001b[0m  0.0226\n",
            "      7        \u001b[36m3.7531\u001b[0m  0.0216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      8        \u001b[36m3.6861\u001b[0m  0.0221\n",
            "      9        \u001b[36m3.6191\u001b[0m  0.0230\n",
            "     10        \u001b[36m3.5520\u001b[0m  0.0231\n",
            "     11        \u001b[36m3.4850\u001b[0m  0.0236\n",
            "     12        \u001b[36m3.4180\u001b[0m  0.0252\n",
            "     13        \u001b[36m3.3511\u001b[0m  0.0206\n",
            "     14        \u001b[36m3.2841\u001b[0m  0.0229\n",
            "     15        \u001b[36m3.2171\u001b[0m  0.0227\n",
            "     16        \u001b[36m3.1501\u001b[0m  0.0244\n",
            "     17        \u001b[36m3.0832\u001b[0m  0.0201\n",
            "     18        \u001b[36m3.0163\u001b[0m  0.0231\n",
            "     19        \u001b[36m2.9494\u001b[0m  0.0225\n",
            "     20        \u001b[36m2.8825\u001b[0m  0.0222\n",
            "     21        \u001b[36m2.8156\u001b[0m  0.0226\n",
            "     22        \u001b[36m2.7488\u001b[0m  0.0211\n",
            "     23        \u001b[36m2.6820\u001b[0m  0.0223\n",
            "     24        \u001b[36m2.6153\u001b[0m  0.0236\n",
            "     25        \u001b[36m2.5486\u001b[0m  0.0206\n",
            "     26        \u001b[36m2.4820\u001b[0m  0.0237\n",
            "     27        \u001b[36m2.4155\u001b[0m  0.0205\n",
            "     28        \u001b[36m2.3491\u001b[0m  0.0241\n",
            "     29        \u001b[36m2.2828\u001b[0m  0.0217\n",
            "     30        \u001b[36m2.2167\u001b[0m  0.0231\n",
            "     31        \u001b[36m2.1507\u001b[0m  0.0221\n",
            "     32        \u001b[36m2.0849\u001b[0m  0.0216\n",
            "     33        \u001b[36m2.0194\u001b[0m  0.0246\n",
            "     34        \u001b[36m1.9541\u001b[0m  0.0246\n",
            "     35        \u001b[36m1.8892\u001b[0m  0.0220\n",
            "     36        \u001b[36m1.8247\u001b[0m  0.0222\n",
            "     37        \u001b[36m1.7607\u001b[0m  0.0230\n",
            "     38        \u001b[36m1.6972\u001b[0m  0.0217\n",
            "     39        \u001b[36m1.6344\u001b[0m  0.0231\n",
            "     40        \u001b[36m1.5724\u001b[0m  0.0221\n",
            "     41        \u001b[36m1.5113\u001b[0m  0.0221\n",
            "     42        \u001b[36m1.4512\u001b[0m  0.0231\n",
            "     43        \u001b[36m1.3924\u001b[0m  0.0220\n",
            "     44        \u001b[36m1.3349\u001b[0m  0.0221\n",
            "     45        \u001b[36m1.2790\u001b[0m  0.0240\n",
            "     46        \u001b[36m1.2249\u001b[0m  0.0251\n",
            "     47        \u001b[36m1.1729\u001b[0m  0.0216\n",
            "     48        \u001b[36m1.1231\u001b[0m  0.0227\n",
            "     49        \u001b[36m1.0757\u001b[0m  0.0225\n",
            "     50        \u001b[36m1.0309\u001b[0m  0.0206\n",
            "     51        \u001b[36m0.9890\u001b[0m  0.0221\n",
            "     52        \u001b[36m0.9500\u001b[0m  0.0224\n",
            "     53        \u001b[36m0.9141\u001b[0m  0.0217\n",
            "     54        \u001b[36m0.8813\u001b[0m  0.0206\n",
            "     55        \u001b[36m0.8516\u001b[0m  0.0221\n",
            "     56        \u001b[36m0.8250\u001b[0m  0.0221\n",
            "     57        \u001b[36m0.8013\u001b[0m  0.0223\n",
            "     58        \u001b[36m0.7805\u001b[0m  0.0236\n",
            "     59        \u001b[36m0.7623\u001b[0m  0.0247\n",
            "     60        \u001b[36m0.7465\u001b[0m  0.0221\n",
            "     61        \u001b[36m0.7329\u001b[0m  0.0216\n",
            "     62        \u001b[36m0.7213\u001b[0m  0.0226\n",
            "     63        \u001b[36m0.7114\u001b[0m  0.0208\n",
            "     64        \u001b[36m0.7031\u001b[0m  0.0231\n",
            "     65        \u001b[36m0.6961\u001b[0m  0.0220\n",
            "     66        \u001b[36m0.6902\u001b[0m  0.0224\n",
            "     67        \u001b[36m0.6853\u001b[0m  0.0236\n",
            "     68        \u001b[36m0.6813\u001b[0m  0.0246\n",
            "     69        \u001b[36m0.6779\u001b[0m  0.0221\n",
            "     70        \u001b[36m0.6751\u001b[0m  0.0226\n",
            "     71        \u001b[36m0.6727\u001b[0m  0.0241\n",
            "     72        \u001b[36m0.6708\u001b[0m  0.0220\n",
            "     73        \u001b[36m0.6692\u001b[0m  0.0216\n",
            "     74        \u001b[36m0.6679\u001b[0m  0.0231\n",
            "     75        \u001b[36m0.6668\u001b[0m  0.0222\n",
            "     76        \u001b[36m0.6659\u001b[0m  0.0230\n",
            "     77        \u001b[36m0.6651\u001b[0m  0.0220\n",
            "     78        \u001b[36m0.6645\u001b[0m  0.0231\n",
            "     79        \u001b[36m0.6640\u001b[0m  0.0230\n",
            "     80        \u001b[36m0.6635\u001b[0m  0.0234\n",
            "     81        \u001b[36m0.6632\u001b[0m  0.0215\n",
            "     82        \u001b[36m0.6629\u001b[0m  0.0221\n",
            "     83        \u001b[36m0.6626\u001b[0m  0.0231\n",
            "     84        \u001b[36m0.6624\u001b[0m  0.0232\n",
            "     85        \u001b[36m0.6622\u001b[0m  0.0241\n",
            "     86        \u001b[36m0.6620\u001b[0m  0.0216\n",
            "     87        \u001b[36m0.6619\u001b[0m  0.0210\n",
            "     88        \u001b[36m0.6618\u001b[0m  0.0230\n",
            "     89        \u001b[36m0.6617\u001b[0m  0.0225\n",
            "     90        \u001b[36m0.6616\u001b[0m  0.0216\n",
            "     91        \u001b[36m0.6615\u001b[0m  0.0226\n",
            "     92        \u001b[36m0.6615\u001b[0m  0.0206\n",
            "     93        \u001b[36m0.6614\u001b[0m  0.0221\n",
            "     94        \u001b[36m0.6614\u001b[0m  0.0232\n",
            "     95        \u001b[36m0.6613\u001b[0m  0.0243\n",
            "     96        \u001b[36m0.6613\u001b[0m  0.0230\n",
            "     97        \u001b[36m0.6613\u001b[0m  0.0241\n",
            "     98        \u001b[36m0.6613\u001b[0m  0.0223\n",
            "     99        \u001b[36m0.6612\u001b[0m  0.0240\n",
            "    100        \u001b[36m0.6612\u001b[0m  0.0212\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m87816.7594\u001b[0m  0.0670\n",
            "      2    \u001b[36m67578.9315\u001b[0m  0.0637\n",
            "      3    \u001b[36m51267.8879\u001b[0m  0.0629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == \"__main__\":\n",
            "c:\\Users\\pc\\Documents\\GitHub\\udemy_deep_learning_pytorch_python\\udemy_deep_learning_pytorch_python\\.venv\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == \"\":\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      4    \u001b[36m38467.3815\u001b[0m  0.0640\n",
            "      5    \u001b[36m28422.5020\u001b[0m  0.0643\n",
            "      6    \u001b[36m20474.0236\u001b[0m  0.0633\n",
            "      7    \u001b[36m14073.4598\u001b[0m  0.0631\n",
            "      8     \u001b[36m8759.0273\u001b[0m  0.0669\n",
            "      9     \u001b[36m4118.9129\u001b[0m  0.0609\n",
            "     10      \u001b[36m574.8676\u001b[0m  0.0650\n",
            "     11      \u001b[36m151.9106\u001b[0m  0.0612\n",
            "     12      \u001b[36m122.1280\u001b[0m  0.0659\n",
            "     13      \u001b[36m103.7969\u001b[0m  0.0649\n",
            "     14       \u001b[36m87.6232\u001b[0m  0.0659\n",
            "     15       \u001b[36m72.9820\u001b[0m  0.0644\n",
            "     16       \u001b[36m64.6275\u001b[0m  0.0641\n",
            "     17       \u001b[36m64.3240\u001b[0m  0.0648\n",
            "     18       \u001b[36m55.6824\u001b[0m  0.0674\n",
            "     19       56.6579  0.0668\n",
            "     20       \u001b[36m54.0908\u001b[0m  0.0661\n",
            "     21       60.3754  0.0650\n",
            "     22       61.2469  0.0614\n",
            "     23       57.6553  0.0675\n",
            "     24       \u001b[36m46.2579\u001b[0m  0.0632\n",
            "     25       \u001b[36m41.6352\u001b[0m  0.0628\n",
            "     26       \u001b[36m38.4564\u001b[0m  0.0641\n",
            "     27       \u001b[36m37.3743\u001b[0m  0.0645\n",
            "     28       40.1999  0.0638\n",
            "     29       48.5139  0.0650\n",
            "     30       54.3047  0.0662\n",
            "     31       55.0084  0.0643\n",
            "     32       46.8410  0.0654\n",
            "     33       51.1857  0.0627\n",
            "     34       53.3760  0.0647\n",
            "     35       49.9222  0.0633\n",
            "     36       50.4891  0.0659\n",
            "     37       42.9831  0.0640\n",
            "     38       42.4607  0.0662\n",
            "     39       48.2281  0.0617\n",
            "     40       51.7803  0.0631\n",
            "     41       42.0948  0.0637\n",
            "     42       46.5653  0.0637\n",
            "     43       40.3081  0.0633\n",
            "     44       46.5630  0.0632\n",
            "     45       \u001b[36m30.9395\u001b[0m  0.0617\n",
            "     46       32.7108  0.0643\n",
            "     47       40.6906  0.0680\n",
            "     48       42.6175  0.0636\n",
            "     49       30.9814  0.0649\n",
            "     50       35.4285  0.0676\n",
            "     51       42.0348  0.0593\n",
            "     52       \u001b[36m29.5544\u001b[0m  0.0677\n",
            "     53       \u001b[36m28.6721\u001b[0m  0.0640\n",
            "     54       \u001b[36m26.6299\u001b[0m  0.0654\n",
            "     55       33.5928  0.0653\n",
            "     56       28.4468  0.0681\n",
            "     57       32.2292  0.0652\n",
            "     58       30.2087  0.0668\n",
            "     59       38.0045  0.0657\n",
            "     60       28.4839  0.0643\n",
            "     61       37.8576  0.0642\n",
            "     62       \u001b[36m26.2994\u001b[0m  0.0649\n",
            "     63       30.5172  0.0639\n",
            "     64       27.2373  0.0609\n",
            "     65       26.9506  0.0628\n",
            "     66       29.8316  0.0612\n",
            "     67       \u001b[36m24.7515\u001b[0m  0.0631\n",
            "     68       \u001b[36m23.0422\u001b[0m  0.0638\n",
            "     69       23.5052  0.0885\n",
            "     70       29.2863  0.0638\n",
            "     71       24.0238  0.0649\n",
            "     72       27.1048  0.0652\n",
            "     73       28.2476  0.0647\n",
            "     74       24.0056  0.0649\n",
            "     75       \u001b[36m21.2894\u001b[0m  0.0642\n",
            "     76       23.6430  0.0641\n",
            "     77       22.4640  0.0639\n",
            "     78       22.8840  0.0652\n",
            "     79       23.0820  0.0662\n",
            "     80       23.8254  0.0629\n",
            "     81       25.1159  0.0644\n",
            "     82       22.2584  0.0679\n",
            "     83       22.7255  0.0637\n",
            "     84       \u001b[36m17.2181\u001b[0m  0.0645\n",
            "     85       22.7698  0.0638\n",
            "     86       23.6477  0.0664\n",
            "     87       24.5005  0.0633\n",
            "     88       24.0948  0.0614\n",
            "     89       24.4029  0.0617\n",
            "     90       25.8983  0.0667\n",
            "     91       24.1557  0.0635\n",
            "     92       17.7271  0.0637\n",
            "     93       \u001b[36m14.6178\u001b[0m  0.0666\n",
            "     94       19.3310  0.0648\n",
            "     95       21.3474  0.0670\n",
            "     96       15.0184  0.0647\n",
            "     97       15.5964  0.0647\n",
            "     98       \u001b[36m11.2842\u001b[0m  0.0662\n",
            "     99       14.2381  0.0631\n",
            "    100       13.6896  0.0693\n"
          ]
        }
      ],
      "source": [
        "grid_search = GridSearchCV(estimator=classificador_sklearn, param_grid=params,\n",
        "                           scoring = 'accuracy', cv = 2)\n",
        "grid_search = grid_search.fit(previsores, classe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AiyX1qXkVH_6"
      },
      "outputs": [],
      "source": [
        "melhores_parametros = grid_search.best_params_\n",
        "melhor_precisao = grid_search.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoCqcsFOVPa_",
        "outputId": "66ffbad8-d3e3-4b07-9337-e4978847dc08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'batch_size': 10,\n",
              " 'criterion': torch.nn.modules.loss.BCEWithLogitsLoss,\n",
              " 'max_epochs': 100,\n",
              " 'module__activation': <function torch.nn.functional.relu(input: torch.Tensor, inplace: bool = False) -> torch.Tensor>,\n",
              " 'module__initializer': <function torch.nn.init._make_deprecate.<locals>.deprecated_init(*args, **kwargs)>,\n",
              " 'module__neurons': 16,\n",
              " 'optimizer': torch.optim.adam.Adam}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "melhores_parametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKCjr94mVYrk",
        "outputId": "ebc20bbc-922d-42b9-a9d8-d6f97740e953"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8383308623671856"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "melhor_precisao"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
